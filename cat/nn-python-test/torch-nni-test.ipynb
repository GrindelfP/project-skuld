{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68836988-588a-4929-bfea-e24c717c1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "080e0c47-d99c-4619-b8e1-ca64997e0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация данных\n",
    "def generate_data(func, n_samples=100):\n",
    "    x = torch.linspace(0, 1, n_samples).unsqueeze(1)  # Входные данные\n",
    "    y = func(x)  # Значения функции\n",
    "    return x, y\n",
    "\n",
    "# Определение функций\n",
    "def cos_func(x):\n",
    "    return torch.cos(x)\n",
    "\n",
    "def exp_func(x):\n",
    "    return torch.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d31bc935-0da1-47c8-88c3-e7b632df3d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layer = nn.Sigmoid()\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a17f2896-175c-4069-9f26-d8102be34593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "def train_model(model, criterion, optimizer, x_train, y_train, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        # Прямой проход\n",
    "        predictions = model(x_train)\n",
    "        loss = criterion(predictions, y_train)\n",
    "\n",
    "        # Обратное распространение и обновление весов\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Печать потерь\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bbfc2b1-bc08-405e-922b-8333478dce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_model(model, n_samples=100):\n",
    "    x = torch.linspace(0, 1, n_samples).unsqueeze(1)  # Точки для интеграции\n",
    "    with torch.no_grad():\n",
    "        y = model(x)\n",
    "    integral = torch.trapz(y.squeeze(), x.squeeze())  # Метод трапеций\n",
    "    return integral.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2364128-79ac-4a95-9de2-c96c8ba6943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_model_analytically(model):\n",
    "    # Извлечение параметров\n",
    "    with torch.no_grad():\n",
    "        W1 = model.input_layer.weight  # W^{(1)}\n",
    "        b1 = model.input_layer.bias    # b^{(1)}\n",
    "        W2 = model.output_layer.weight  # W^{(2)}\n",
    "        b2 = model.output_layer.bias    # b^{(2)}\n",
    "\n",
    "    # Сигмоида\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "    def sigmoid_integral(a, b, x_min, x_max):\n",
    "        \"\"\"\n",
    "        Вычисляет аналитический интеграл сигмоиды: ∫ σ(ax + b) dx\n",
    "        \"\"\"\n",
    "        if a == 0:\n",
    "            raise ValueError(\"Параметр 'a' не может быть равен нулю для корректного вычисления.\")\n",
    "        \n",
    "        # Преобразуем параметры в тензоры\n",
    "        a = torch.tensor(a, dtype=torch.float32)\n",
    "        b = torch.tensor(b, dtype=torch.float32)\n",
    "        x_min = torch.tensor(x_min, dtype=torch.float32)\n",
    "        x_max = torch.tensor(x_max, dtype=torch.float32)\n",
    "        \n",
    "        # Вычисляем аналитический интеграл\n",
    "        return (1 / a) * (\n",
    "            torch.log(1 + torch.exp(a * x_max + b)) - torch.log(1 + torch.exp(a * x_min + b))\n",
    "        )\n",
    "\n",
    "    # Интеграл: ∫ f(X) dX = ∫ (b^{(2)} + W^{(2)T} φ(b^{(1)} + W^{(1)}X)) dX\n",
    "    x_min, x_max = 0, 1  # Пределы интегрирования\n",
    "    integral = b2.item() * (x_max - x_min)  # Член b^{(2)}\n",
    "\n",
    "    for i in range(W2.size(1)):  # По скрытым нейронам\n",
    "        for j in range(W1.size(1)):  # По входным переменным\n",
    "            a = W1[i, j].item()\n",
    "            b = b1[i].item()\n",
    "            weight = W2[0, i].item()\n",
    "            integral += weight * sigmoid_integral(a, b, x_min, x_max)\n",
    "\n",
    "    return integral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7a006-d08a-49f5-847e-7cb6bbdc5ddc",
   "metadata": {},
   "source": [
    "## 1D exp[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8afab6a-15b0-4802-b363-8896b7959e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "input_size = 1  # Одна переменная x\n",
    "hidden_size = 10  # Количество нейронов в скрытом слое\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10000\n",
    "\n",
    "# Создаем модель\n",
    "model = MLP(input_size, hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2efdd7a4-f6be-4288-824a-85df561ee101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация данных\n",
    "x_train, y_train = generate_data(exp_func, 10000)  # Используем cos(x) или exp_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f40a0855-2e3c-43e0-97d0-c025adef8ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.128916\n",
      "Epoch [200/10000], Loss: 0.059543\n",
      "Epoch [300/10000], Loss: 0.015104\n",
      "Epoch [400/10000], Loss: 0.004839\n",
      "Epoch [500/10000], Loss: 0.003649\n",
      "Epoch [600/10000], Loss: 0.003084\n",
      "Epoch [700/10000], Loss: 0.002617\n",
      "Epoch [800/10000], Loss: 0.002222\n",
      "Epoch [900/10000], Loss: 0.001885\n",
      "Epoch [1000/10000], Loss: 0.001593\n",
      "Epoch [1100/10000], Loss: 0.001338\n",
      "Epoch [1200/10000], Loss: 0.001114\n",
      "Epoch [1300/10000], Loss: 0.000917\n",
      "Epoch [1400/10000], Loss: 0.000747\n",
      "Epoch [1500/10000], Loss: 0.000600\n",
      "Epoch [1600/10000], Loss: 0.000475\n",
      "Epoch [1700/10000], Loss: 0.000372\n",
      "Epoch [1800/10000], Loss: 0.000288\n",
      "Epoch [1900/10000], Loss: 0.000221\n",
      "Epoch [2000/10000], Loss: 0.000169\n",
      "Epoch [2100/10000], Loss: 0.000130\n",
      "Epoch [2200/10000], Loss: 0.000101\n",
      "Epoch [2300/10000], Loss: 0.000080\n",
      "Epoch [2400/10000], Loss: 0.000066\n",
      "Epoch [2500/10000], Loss: 0.000056\n",
      "Epoch [2600/10000], Loss: 0.000048\n",
      "Epoch [2700/10000], Loss: 0.000043\n",
      "Epoch [2800/10000], Loss: 0.000040\n",
      "Epoch [2900/10000], Loss: 0.000037\n",
      "Epoch [3000/10000], Loss: 0.000035\n",
      "Epoch [3100/10000], Loss: 0.000032\n",
      "Epoch [3200/10000], Loss: 0.000031\n",
      "Epoch [3300/10000], Loss: 0.000029\n",
      "Epoch [3400/10000], Loss: 0.000027\n",
      "Epoch [3500/10000], Loss: 0.000026\n",
      "Epoch [3600/10000], Loss: 0.000024\n",
      "Epoch [3700/10000], Loss: 0.000023\n",
      "Epoch [3800/10000], Loss: 0.000022\n",
      "Epoch [3900/10000], Loss: 0.000021\n",
      "Epoch [4000/10000], Loss: 0.000019\n",
      "Epoch [4100/10000], Loss: 0.000018\n",
      "Epoch [4200/10000], Loss: 0.000017\n",
      "Epoch [4300/10000], Loss: 0.000016\n",
      "Epoch [4400/10000], Loss: 0.000015\n",
      "Epoch [4500/10000], Loss: 0.000014\n",
      "Epoch [4600/10000], Loss: 0.000013\n",
      "Epoch [4700/10000], Loss: 0.000012\n",
      "Epoch [4800/10000], Loss: 0.000012\n",
      "Epoch [4900/10000], Loss: 0.000011\n",
      "Epoch [5000/10000], Loss: 0.000010\n",
      "Epoch [5100/10000], Loss: 0.000009\n",
      "Epoch [5200/10000], Loss: 0.000009\n",
      "Epoch [5300/10000], Loss: 0.000008\n",
      "Epoch [5400/10000], Loss: 0.000008\n",
      "Epoch [5500/10000], Loss: 0.000007\n",
      "Epoch [5600/10000], Loss: 0.000006\n",
      "Epoch [5700/10000], Loss: 0.000006\n",
      "Epoch [5800/10000], Loss: 0.000006\n",
      "Epoch [5900/10000], Loss: 0.000005\n",
      "Epoch [6000/10000], Loss: 0.000005\n",
      "Epoch [6100/10000], Loss: 0.000004\n",
      "Epoch [6200/10000], Loss: 0.000004\n",
      "Epoch [6300/10000], Loss: 0.000004\n",
      "Epoch [6400/10000], Loss: 0.000003\n",
      "Epoch [6500/10000], Loss: 0.000003\n",
      "Epoch [6600/10000], Loss: 0.000003\n",
      "Epoch [6700/10000], Loss: 0.000003\n",
      "Epoch [6800/10000], Loss: 0.000002\n",
      "Epoch [6900/10000], Loss: 0.000002\n",
      "Epoch [7000/10000], Loss: 0.000002\n",
      "Epoch [7100/10000], Loss: 0.000002\n",
      "Epoch [7200/10000], Loss: 0.000002\n",
      "Epoch [7300/10000], Loss: 0.000002\n",
      "Epoch [7400/10000], Loss: 0.000002\n",
      "Epoch [7500/10000], Loss: 0.000002\n",
      "Epoch [7600/10000], Loss: 0.000001\n",
      "Epoch [7700/10000], Loss: 0.000001\n",
      "Epoch [7800/10000], Loss: 0.000001\n",
      "Epoch [7900/10000], Loss: 0.000001\n",
      "Epoch [8000/10000], Loss: 0.000001\n",
      "Epoch [8100/10000], Loss: 0.000001\n",
      "Epoch [8200/10000], Loss: 0.000002\n",
      "Epoch [8300/10000], Loss: 0.000001\n",
      "Epoch [8400/10000], Loss: 0.000001\n",
      "Epoch [8500/10000], Loss: 0.000001\n",
      "Epoch [8600/10000], Loss: 0.000001\n",
      "Epoch [8700/10000], Loss: 0.000001\n",
      "Epoch [8800/10000], Loss: 0.000001\n",
      "Epoch [8900/10000], Loss: 0.000001\n",
      "Epoch [9000/10000], Loss: 0.000001\n",
      "Epoch [9100/10000], Loss: 0.000001\n",
      "Epoch [9200/10000], Loss: 0.000001\n",
      "Epoch [9300/10000], Loss: 0.000001\n",
      "Epoch [9400/10000], Loss: 0.000008\n",
      "Epoch [9500/10000], Loss: 0.000001\n",
      "Epoch [9600/10000], Loss: 0.000001\n",
      "Epoch [9700/10000], Loss: 0.000002\n",
      "Epoch [9800/10000], Loss: 0.000001\n",
      "Epoch [9900/10000], Loss: 0.000001\n",
      "Epoch [10000/10000], Loss: 0.000001\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "train_model(model, criterion, optimizer, x_train, y_train, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce2befc1-cdce-4e6a-9812-18f0916b46af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приближенное значение интеграла: 1.718310\n"
     ]
    }
   ],
   "source": [
    "# Вычисление интеграла\n",
    "integral = integrate_model(model)\n",
    "print(f'Приближенное значение интеграла: {integral:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "680a638e-3030-4dfc-9ff1-77d526e7072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точное значение интеграла: 1.718282\n"
     ]
    }
   ],
   "source": [
    "# Для сравнения: точное значение интеграла\n",
    "true_integral = np.exp(1) - np.exp(0)  # Для cos(x)\n",
    "print(f'Точное значение интеграла: {true_integral.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d5e0f84-55d9-4ea1-b4cf-4a9509556ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аналитическое значение интеграла нейросети: 1.718296\n"
     ]
    }
   ],
   "source": [
    "# Вычисление интеграла аналитически\n",
    "integral_analytical = integrate_model_analytically(model)\n",
    "print(f'Аналитическое значение интеграла нейросети: {integral_analytical:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118ee478-18c7-40ae-8550-e6e5e3fc5d5d",
   "metadata": {},
   "source": [
    "## 1D cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "218d1c52-667f-4888-9862-603d2fcacdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель\n",
    "model = MLP(input_size, hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "797d37ae-5f8f-4eb0-a208-857d446eab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация данных\n",
    "x_train, y_train = generate_data(cos_func, 10000)  # Используем cos(x) или exp_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df6edcaf-93b5-4e8b-95dd-3790e131a96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.007816\n",
      "Epoch [200/10000], Loss: 0.002053\n",
      "Epoch [300/10000], Loss: 0.001363\n",
      "Epoch [400/10000], Loss: 0.001294\n",
      "Epoch [500/10000], Loss: 0.001235\n",
      "Epoch [600/10000], Loss: 0.001180\n",
      "Epoch [700/10000], Loss: 0.001129\n",
      "Epoch [800/10000], Loss: 0.001082\n",
      "Epoch [900/10000], Loss: 0.001039\n",
      "Epoch [1000/10000], Loss: 0.000999\n",
      "Epoch [1100/10000], Loss: 0.000959\n",
      "Epoch [1200/10000], Loss: 0.000920\n",
      "Epoch [1300/10000], Loss: 0.000881\n",
      "Epoch [1400/10000], Loss: 0.000840\n",
      "Epoch [1500/10000], Loss: 0.000796\n",
      "Epoch [1600/10000], Loss: 0.000749\n",
      "Epoch [1700/10000], Loss: 0.000697\n",
      "Epoch [1800/10000], Loss: 0.000639\n",
      "Epoch [1900/10000], Loss: 0.000576\n",
      "Epoch [2000/10000], Loss: 0.000507\n",
      "Epoch [2100/10000], Loss: 0.000434\n",
      "Epoch [2200/10000], Loss: 0.000358\n",
      "Epoch [2300/10000], Loss: 0.000282\n",
      "Epoch [2400/10000], Loss: 0.000211\n",
      "Epoch [2500/10000], Loss: 0.000149\n",
      "Epoch [2600/10000], Loss: 0.000098\n",
      "Epoch [2700/10000], Loss: 0.000061\n",
      "Epoch [2800/10000], Loss: 0.000036\n",
      "Epoch [2900/10000], Loss: 0.000021\n",
      "Epoch [3000/10000], Loss: 0.000013\n",
      "Epoch [3100/10000], Loss: 0.000008\n",
      "Epoch [3200/10000], Loss: 0.000006\n",
      "Epoch [3300/10000], Loss: 0.000005\n",
      "Epoch [3400/10000], Loss: 0.000005\n",
      "Epoch [3500/10000], Loss: 0.000005\n",
      "Epoch [3600/10000], Loss: 0.000005\n",
      "Epoch [3700/10000], Loss: 0.000005\n",
      "Epoch [3800/10000], Loss: 0.000005\n",
      "Epoch [3900/10000], Loss: 0.000004\n",
      "Epoch [4000/10000], Loss: 0.000004\n",
      "Epoch [4100/10000], Loss: 0.000004\n",
      "Epoch [4200/10000], Loss: 0.000004\n",
      "Epoch [4300/10000], Loss: 0.000004\n",
      "Epoch [4400/10000], Loss: 0.000004\n",
      "Epoch [4500/10000], Loss: 0.000004\n",
      "Epoch [4600/10000], Loss: 0.000004\n",
      "Epoch [4700/10000], Loss: 0.000004\n",
      "Epoch [4800/10000], Loss: 0.000004\n",
      "Epoch [4900/10000], Loss: 0.000004\n",
      "Epoch [5000/10000], Loss: 0.000004\n",
      "Epoch [5100/10000], Loss: 0.000004\n",
      "Epoch [5200/10000], Loss: 0.000004\n",
      "Epoch [5300/10000], Loss: 0.000004\n",
      "Epoch [5400/10000], Loss: 0.000004\n",
      "Epoch [5500/10000], Loss: 0.000004\n",
      "Epoch [5600/10000], Loss: 0.000004\n",
      "Epoch [5700/10000], Loss: 0.000004\n",
      "Epoch [5800/10000], Loss: 0.000004\n",
      "Epoch [5900/10000], Loss: 0.000004\n",
      "Epoch [6000/10000], Loss: 0.000004\n",
      "Epoch [6100/10000], Loss: 0.000004\n",
      "Epoch [6200/10000], Loss: 0.000004\n",
      "Epoch [6300/10000], Loss: 0.000003\n",
      "Epoch [6400/10000], Loss: 0.000003\n",
      "Epoch [6500/10000], Loss: 0.000054\n",
      "Epoch [6600/10000], Loss: 0.000003\n",
      "Epoch [6700/10000], Loss: 0.000003\n",
      "Epoch [6800/10000], Loss: 0.000003\n",
      "Epoch [6900/10000], Loss: 0.000003\n",
      "Epoch [7000/10000], Loss: 0.000003\n",
      "Epoch [7100/10000], Loss: 0.000003\n",
      "Epoch [7200/10000], Loss: 0.000003\n",
      "Epoch [7300/10000], Loss: 0.000003\n",
      "Epoch [7400/10000], Loss: 0.000003\n",
      "Epoch [7500/10000], Loss: 0.000003\n",
      "Epoch [7600/10000], Loss: 0.000003\n",
      "Epoch [7700/10000], Loss: 0.000003\n",
      "Epoch [7800/10000], Loss: 0.000003\n",
      "Epoch [7900/10000], Loss: 0.000004\n",
      "Epoch [8000/10000], Loss: 0.000003\n",
      "Epoch [8100/10000], Loss: 0.000003\n",
      "Epoch [8200/10000], Loss: 0.000003\n",
      "Epoch [8300/10000], Loss: 0.000003\n",
      "Epoch [8400/10000], Loss: 0.000003\n",
      "Epoch [8500/10000], Loss: 0.000005\n",
      "Epoch [8600/10000], Loss: 0.000003\n",
      "Epoch [8700/10000], Loss: 0.000003\n",
      "Epoch [8800/10000], Loss: 0.000006\n",
      "Epoch [8900/10000], Loss: 0.000003\n",
      "Epoch [9000/10000], Loss: 0.000003\n",
      "Epoch [9100/10000], Loss: 0.000003\n",
      "Epoch [9200/10000], Loss: 0.000003\n",
      "Epoch [9300/10000], Loss: 0.000010\n",
      "Epoch [9400/10000], Loss: 0.000003\n",
      "Epoch [9500/10000], Loss: 0.000003\n",
      "Epoch [9600/10000], Loss: 0.000011\n",
      "Epoch [9700/10000], Loss: 0.000003\n",
      "Epoch [9800/10000], Loss: 0.000003\n",
      "Epoch [9900/10000], Loss: 0.000012\n",
      "Epoch [10000/10000], Loss: 0.000003\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "train_model(model, criterion, optimizer, x_train, y_train, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07ca3cd8-84b9-4657-9690-7bb88534b14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Приближенное значение интеграла: 0.841498\n"
     ]
    }
   ],
   "source": [
    "# Вычисление интеграла\n",
    "integral = integrate_model(model)\n",
    "print(f'Приближенное значение интеграла: {integral:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d3e1fe84-ff9e-46d3-afe9-f796e8556fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точное значение интеграла: 0.841471\n"
     ]
    }
   ],
   "source": [
    "# Для сравнения: точное значение интеграла\n",
    "true_integral = np.sin(1) - np.sin(0)  # Для cos(x)\n",
    "print(f'Точное значение интеграла: {true_integral.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6fbd096-9403-416d-b375-d9e7c5b987e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аналитическое значение интеграла нейросети: 0.841504\n"
     ]
    }
   ],
   "source": [
    "# Вычисление интеграла аналитически\n",
    "integral_analytical = integrate_model_analytically(model)\n",
    "print(f'Аналитическое значение интеграла нейросети: {integral_analytical:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa04572f-3a78-446f-a8dc-49a6c7ffb363",
   "metadata": {},
   "source": [
    "## 2D $sin(x) + cos(y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7551e61a-26c3-4e46-a1dc-5bcd1116fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_model_2d_analytically(model, x_min, x_max, y_min, y_max):\n",
    "    \"\"\"\n",
    "    Интегрирует нейронную сеть с 2 входами по обеим переменным аналитически.\n",
    "    \"\"\"\n",
    "    # Извлечение параметров сети\n",
    "    with torch.no_grad():\n",
    "        W1 = model.input_layer.weight  # W^{(1)}: веса входного слоя\n",
    "        b1 = model.input_layer.bias    # b^{(1)}: смещения входного слоя\n",
    "        W2 = model.output_layer.weight  # W^{(2)}: веса выходного слоя\n",
    "        b2 = model.output_layer.bias    # b^{(2)}: смещение выходного слоя\n",
    "\n",
    "    # Сигмоида и её интеграл\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "    def sigmoid_integral(a, b, x_min, x_max):\n",
    "        \"\"\"\n",
    "        Вычисляет аналитический интеграл сигмоиды: ∫ σ(ax + b) dx\n",
    "        \"\"\"\n",
    "        if a == 0:\n",
    "            raise ValueError(\"Параметр 'a' не может быть равен нулю для корректного вычисления.\")\n",
    "        \n",
    "        # Преобразуем все параметры в тензоры, чтобы обеспечить правильную работу с PyTorch\n",
    "        a = torch.tensor(a, dtype=torch.float32)\n",
    "        b = torch.tensor(b, dtype=torch.float32)\n",
    "        x_min = torch.tensor(x_min, dtype=torch.float32)\n",
    "        x_max = torch.tensor(x_max, dtype=torch.float32)\n",
    "    \n",
    "        return (1 / a) * (\n",
    "            torch.log(1 + torch.exp(a * x_max + b)) - torch.log(1 + torch.exp(a * x_min + b))\n",
    "        )\n",
    "\n",
    "\n",
    "    # Интеграл: ∫ f(x, y) dx dy\n",
    "    integral = b2.item() * (x_max - x_min) * (y_max - y_min)  # Член b^{(2)}\n",
    "\n",
    "    for i in range(W2.size(1)):  # По скрытым нейронам\n",
    "        weight = W2[0, i].item()  # W^{(2)}\n",
    "\n",
    "        # Интегрируем по каждой переменной\n",
    "        for j_x, j_y in [(0, 0), (0, 1), (1, 0), (1, 1)]:  # Индексы весов W^{(1)}\n",
    "            a_x = W1[i, j_x].item()  # Вес для x\n",
    "            a_y = W1[i, j_y].item()  # Вес для y\n",
    "            b = b1[i].item()         # Смещение\n",
    "\n",
    "            # Интеграция по y\n",
    "            inner_integral = sigmoid_integral(a_y, b, y_min, y_max)\n",
    "            # Интеграция по x\n",
    "            integral += weight * sigmoid_integral(a_x, inner_integral, x_min, x_max)\n",
    "\n",
    "    return integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e0e059f-03f7-4dcd-9a2c-c4519405c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "input_dim = 2  # Два входа: x и y\n",
    "hidden_dim = 10  # Размер скрытого слоя\n",
    "output_dim = 1  # Один выход\n",
    "learning_rate = 0.01\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c664a8d-a980-4f64-b327-e26f621edc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель\n",
    "model = MLP(input_dim, hidden_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b0a6ba7-5b91-493b-ade6-77df222f661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2D_data(num_samples):\n",
    "    x = torch.rand(num_samples, 1)\n",
    "    y = torch.rand(num_samples, 1)\n",
    "    f_values = torch.sin(x) + torch.cos(y)\n",
    "    return torch.cat((x, y), dim=1), f_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b91a23cb-f6d0-4139-83ae-def8b5c8b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация данных\n",
    "X_train, y_train = generate_2D_data(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "daf055fb-6ee3-445e-9cda-1dddc805f5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/10000], Loss: 0.0813\n",
      "Epoch [100/10000], Loss: 0.0581\n",
      "Epoch [150/10000], Loss: 0.0316\n",
      "Epoch [200/10000], Loss: 0.0182\n",
      "Epoch [250/10000], Loss: 0.0065\n",
      "Epoch [300/10000], Loss: 0.0025\n",
      "Epoch [350/10000], Loss: 0.0014\n",
      "Epoch [400/10000], Loss: 0.0011\n",
      "Epoch [450/10000], Loss: 0.0012\n",
      "Epoch [500/10000], Loss: 0.0011\n",
      "Epoch [550/10000], Loss: 0.0012\n",
      "Epoch [600/10000], Loss: 0.0012\n",
      "Epoch [650/10000], Loss: 0.0011\n",
      "Epoch [700/10000], Loss: 0.0011\n",
      "Epoch [750/10000], Loss: 0.0011\n",
      "Epoch [800/10000], Loss: 0.0011\n",
      "Epoch [850/10000], Loss: 0.0011\n",
      "Epoch [900/10000], Loss: 0.0010\n",
      "Epoch [950/10000], Loss: 0.0011\n",
      "Epoch [1000/10000], Loss: 0.0011\n",
      "Epoch [1050/10000], Loss: 0.0011\n",
      "Epoch [1100/10000], Loss: 0.0011\n",
      "Epoch [1150/10000], Loss: 0.0011\n",
      "Epoch [1200/10000], Loss: 0.0010\n",
      "Epoch [1250/10000], Loss: 0.0010\n",
      "Epoch [1300/10000], Loss: 0.0010\n",
      "Epoch [1350/10000], Loss: 0.0010\n",
      "Epoch [1400/10000], Loss: 0.0011\n",
      "Epoch [1450/10000], Loss: 0.0010\n",
      "Epoch [1500/10000], Loss: 0.0010\n",
      "Epoch [1550/10000], Loss: 0.0011\n",
      "Epoch [1600/10000], Loss: 0.0010\n",
      "Epoch [1650/10000], Loss: 0.0010\n",
      "Epoch [1700/10000], Loss: 0.0010\n",
      "Epoch [1750/10000], Loss: 0.0010\n",
      "Epoch [1800/10000], Loss: 0.0010\n",
      "Epoch [1850/10000], Loss: 0.0010\n",
      "Epoch [1900/10000], Loss: 0.0010\n",
      "Epoch [1950/10000], Loss: 0.0009\n",
      "Epoch [2000/10000], Loss: 0.0009\n",
      "Epoch [2050/10000], Loss: 0.0010\n",
      "Epoch [2100/10000], Loss: 0.0009\n",
      "Epoch [2150/10000], Loss: 0.0009\n",
      "Epoch [2200/10000], Loss: 0.0009\n",
      "Epoch [2250/10000], Loss: 0.0010\n",
      "Epoch [2300/10000], Loss: 0.0009\n",
      "Epoch [2350/10000], Loss: 0.0009\n",
      "Epoch [2400/10000], Loss: 0.0008\n",
      "Epoch [2450/10000], Loss: 0.0008\n",
      "Epoch [2500/10000], Loss: 0.0009\n",
      "Epoch [2550/10000], Loss: 0.0008\n",
      "Epoch [2600/10000], Loss: 0.0007\n",
      "Epoch [2650/10000], Loss: 0.0007\n",
      "Epoch [2700/10000], Loss: 0.0007\n",
      "Epoch [2750/10000], Loss: 0.0006\n",
      "Epoch [2800/10000], Loss: 0.0006\n",
      "Epoch [2850/10000], Loss: 0.0005\n",
      "Epoch [2900/10000], Loss: 0.0005\n",
      "Epoch [2950/10000], Loss: 0.0004\n",
      "Epoch [3000/10000], Loss: 0.0003\n",
      "Epoch [3050/10000], Loss: 0.0003\n",
      "Epoch [3100/10000], Loss: 0.0003\n",
      "Epoch [3150/10000], Loss: 0.0002\n",
      "Epoch [3200/10000], Loss: 0.0002\n",
      "Epoch [3250/10000], Loss: 0.0001\n",
      "Epoch [3300/10000], Loss: 0.0001\n",
      "Epoch [3350/10000], Loss: 0.0001\n",
      "Epoch [3400/10000], Loss: 0.0001\n",
      "Epoch [3450/10000], Loss: 0.0001\n",
      "Epoch [3500/10000], Loss: 0.0001\n",
      "Epoch [3550/10000], Loss: 0.0001\n",
      "Epoch [3600/10000], Loss: 0.0001\n",
      "Epoch [3650/10000], Loss: 0.0000\n",
      "Epoch [3700/10000], Loss: 0.0000\n",
      "Epoch [3750/10000], Loss: 0.0000\n",
      "Epoch [3800/10000], Loss: 0.0000\n",
      "Epoch [3850/10000], Loss: 0.0000\n",
      "Epoch [3900/10000], Loss: 0.0000\n",
      "Epoch [3950/10000], Loss: 0.0000\n",
      "Epoch [4000/10000], Loss: 0.0000\n",
      "Epoch [4050/10000], Loss: 0.0000\n",
      "Epoch [4100/10000], Loss: 0.0000\n",
      "Epoch [4150/10000], Loss: 0.0000\n",
      "Epoch [4200/10000], Loss: 0.0000\n",
      "Epoch [4250/10000], Loss: 0.0000\n",
      "Epoch [4300/10000], Loss: 0.0000\n",
      "Epoch [4350/10000], Loss: 0.0000\n",
      "Epoch [4400/10000], Loss: 0.0000\n",
      "Epoch [4450/10000], Loss: 0.0000\n",
      "Epoch [4500/10000], Loss: 0.0000\n",
      "Epoch [4550/10000], Loss: 0.0000\n",
      "Epoch [4600/10000], Loss: 0.0000\n",
      "Epoch [4650/10000], Loss: 0.0000\n",
      "Epoch [4700/10000], Loss: 0.0000\n",
      "Epoch [4750/10000], Loss: 0.0000\n",
      "Epoch [4800/10000], Loss: 0.0000\n",
      "Epoch [4850/10000], Loss: 0.0000\n",
      "Epoch [4900/10000], Loss: 0.0000\n",
      "Epoch [4950/10000], Loss: 0.0000\n",
      "Epoch [5000/10000], Loss: 0.0000\n",
      "Epoch [5050/10000], Loss: 0.0000\n",
      "Epoch [5100/10000], Loss: 0.0000\n",
      "Epoch [5150/10000], Loss: 0.0000\n",
      "Epoch [5200/10000], Loss: 0.0000\n",
      "Epoch [5250/10000], Loss: 0.0000\n",
      "Epoch [5300/10000], Loss: 0.0000\n",
      "Epoch [5350/10000], Loss: 0.0000\n",
      "Epoch [5400/10000], Loss: 0.0000\n",
      "Epoch [5450/10000], Loss: 0.0000\n",
      "Epoch [5500/10000], Loss: 0.0000\n",
      "Epoch [5550/10000], Loss: 0.0000\n",
      "Epoch [5600/10000], Loss: 0.0000\n",
      "Epoch [5650/10000], Loss: 0.0000\n",
      "Epoch [5700/10000], Loss: 0.0000\n",
      "Epoch [5750/10000], Loss: 0.0000\n",
      "Epoch [5800/10000], Loss: 0.0000\n",
      "Epoch [5850/10000], Loss: 0.0000\n",
      "Epoch [5900/10000], Loss: 0.0000\n",
      "Epoch [5950/10000], Loss: 0.0000\n",
      "Epoch [6000/10000], Loss: 0.0000\n",
      "Epoch [6050/10000], Loss: 0.0000\n",
      "Epoch [6100/10000], Loss: 0.0000\n",
      "Epoch [6150/10000], Loss: 0.0000\n",
      "Epoch [6200/10000], Loss: 0.0000\n",
      "Epoch [6250/10000], Loss: 0.0000\n",
      "Epoch [6300/10000], Loss: 0.0000\n",
      "Epoch [6350/10000], Loss: 0.0000\n",
      "Epoch [6400/10000], Loss: 0.0000\n",
      "Epoch [6450/10000], Loss: 0.0000\n",
      "Epoch [6500/10000], Loss: 0.0000\n",
      "Epoch [6550/10000], Loss: 0.0000\n",
      "Epoch [6600/10000], Loss: 0.0000\n",
      "Epoch [6650/10000], Loss: 0.0000\n",
      "Epoch [6700/10000], Loss: 0.0000\n",
      "Epoch [6750/10000], Loss: 0.0000\n",
      "Epoch [6800/10000], Loss: 0.0000\n",
      "Epoch [6850/10000], Loss: 0.0000\n",
      "Epoch [6900/10000], Loss: 0.0000\n",
      "Epoch [6950/10000], Loss: 0.0000\n",
      "Epoch [7000/10000], Loss: 0.0000\n",
      "Epoch [7050/10000], Loss: 0.0000\n",
      "Epoch [7100/10000], Loss: 0.0000\n",
      "Epoch [7150/10000], Loss: 0.0000\n",
      "Epoch [7200/10000], Loss: 0.0000\n",
      "Epoch [7250/10000], Loss: 0.0000\n",
      "Epoch [7300/10000], Loss: 0.0000\n",
      "Epoch [7350/10000], Loss: 0.0000\n",
      "Epoch [7400/10000], Loss: 0.0000\n",
      "Epoch [7450/10000], Loss: 0.0000\n",
      "Epoch [7500/10000], Loss: 0.0000\n",
      "Epoch [7550/10000], Loss: 0.0000\n",
      "Epoch [7600/10000], Loss: 0.0000\n",
      "Epoch [7650/10000], Loss: 0.0000\n",
      "Epoch [7700/10000], Loss: 0.0000\n",
      "Epoch [7750/10000], Loss: 0.0000\n",
      "Epoch [7800/10000], Loss: 0.0000\n",
      "Epoch [7850/10000], Loss: 0.0000\n",
      "Epoch [7900/10000], Loss: 0.0000\n",
      "Epoch [7950/10000], Loss: 0.0000\n",
      "Epoch [8000/10000], Loss: 0.0000\n",
      "Epoch [8050/10000], Loss: 0.0000\n",
      "Epoch [8100/10000], Loss: 0.0000\n",
      "Epoch [8150/10000], Loss: 0.0000\n",
      "Epoch [8200/10000], Loss: 0.0000\n",
      "Epoch [8250/10000], Loss: 0.0000\n",
      "Epoch [8300/10000], Loss: 0.0000\n",
      "Epoch [8350/10000], Loss: 0.0000\n",
      "Epoch [8400/10000], Loss: 0.0000\n",
      "Epoch [8450/10000], Loss: 0.0000\n",
      "Epoch [8500/10000], Loss: 0.0000\n",
      "Epoch [8550/10000], Loss: 0.0000\n",
      "Epoch [8600/10000], Loss: 0.0000\n",
      "Epoch [8650/10000], Loss: 0.0000\n",
      "Epoch [8700/10000], Loss: 0.0000\n",
      "Epoch [8750/10000], Loss: 0.0000\n",
      "Epoch [8800/10000], Loss: 0.0000\n",
      "Epoch [8850/10000], Loss: 0.0000\n",
      "Epoch [8900/10000], Loss: 0.0000\n",
      "Epoch [8950/10000], Loss: 0.0000\n",
      "Epoch [9000/10000], Loss: 0.0000\n",
      "Epoch [9050/10000], Loss: 0.0000\n",
      "Epoch [9100/10000], Loss: 0.0000\n",
      "Epoch [9150/10000], Loss: 0.0000\n",
      "Epoch [9200/10000], Loss: 0.0000\n",
      "Epoch [9250/10000], Loss: 0.0000\n",
      "Epoch [9300/10000], Loss: 0.0000\n",
      "Epoch [9350/10000], Loss: 0.0000\n",
      "Epoch [9400/10000], Loss: 0.0000\n",
      "Epoch [9450/10000], Loss: 0.0000\n",
      "Epoch [9500/10000], Loss: 0.0000\n",
      "Epoch [9550/10000], Loss: 0.0000\n",
      "Epoch [9600/10000], Loss: 0.0000\n",
      "Epoch [9650/10000], Loss: 0.0000\n",
      "Epoch [9700/10000], Loss: 0.0000\n",
      "Epoch [9750/10000], Loss: 0.0000\n",
      "Epoch [9800/10000], Loss: 0.0000\n",
      "Epoch [9850/10000], Loss: 0.0000\n",
      "Epoch [9900/10000], Loss: 0.0000\n",
      "Epoch [9950/10000], Loss: 0.0000\n",
      "Epoch [10000/10000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Генерация данных\n",
    "    X_train, y_train = generate_data(1000)\n",
    "    \n",
    "    # Обучение\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "856c5c68-adf8-4509-a5d9-fa24b0173014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аналитическое значение двойного интеграла нейросети: 3.633325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/v02b0vfx2tbc5plrdx4v6gk80000gn/T/ipykernel_14564/2003117665.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  b = torch.tensor(b, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Пределы интегрирования\n",
    "x_min, x_max = 0, 1\n",
    "y_min, y_max = 0, 1\n",
    "\n",
    "# Вычисление интеграла нейросети\n",
    "integral_2d_analytical = integrate_model_2d_analytically(model, x_min, x_max, y_min, y_max)\n",
    "print(f'Аналитическое значение двойного интеграла нейросети: {integral_2d_analytical:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "76642646-bbd2-4c67-94f5-301d99bd1605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение аналитического интеграла: 1.301169\n"
     ]
    }
   ],
   "source": [
    "# Значения для cos(1) и sin(1)\n",
    "cos_1 = np.cos(1)\n",
    "sin_1 = np.sin(1)\n",
    "\n",
    "# Аналитический интеграл\n",
    "true_integral = (1 - cos_1) + sin_1\n",
    "print(f\"Значение аналитического интеграла: {true_integral:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43db4a-d54e-4831-a21b-b8e443ceaaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
