{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46f1260-cb49-41b5-b222-cf7514ebfa26",
   "metadata": {},
   "source": [
    "# Torch Neural Network Integration with custom integration function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f332b-fe2b-4c53-9d70-4d9eba09061c",
   "metadata": {},
   "source": [
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b44e85b-2955-4da7-8784-cf36ac153fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from mpmath import polylog, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cec9f5-6de3-4867-b818-e8152ad3d11a",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a15a0-1572-4e62-9d31-df1b75276039",
   "metadata": {},
   "source": [
    "### Neural Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27041c02-f514-4492-a4e4-18a308afe158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layer = nn.Sigmoid()\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03023775-84b5-4ac0-8ef4-b02310909287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, x_train, y_train, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        predictions = model(x_train)\n",
    "        loss = criterion(predictions, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc435e3-0a6f-4374-a5f9-614d11de8b1b",
   "metadata": {},
   "source": [
    "### NN custom integration function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c882d6-f634-4c49-a568-603bb24595fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NN_analytical_integral(alpha, beta, b1, b2, weights_w1, weights_w2):\n",
    "\n",
    "    def compute_phi_j(b1_j, w1_j, alpha, beta):\n",
    "        term_alpha = polylog(1, -exp(-b1_j - w1_j * alpha))\n",
    "        term_beta = polylog(1, -exp(-b1_j - w1_j * beta))\n",
    "        return term_alpha - term_beta\n",
    "\n",
    "    integral_sum = 0\n",
    "    for w2, w1, b1_j in zip(weights_w2, weights_w1, b1):\n",
    "        phi_j = compute_phi_j(b1_j, w1, alpha, beta)\n",
    "        integral_sum += w2 * ((beta - alpha) + phi_j / w1)\n",
    "    \n",
    "    return b2 * (beta - alpha) + integral_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad98c2e-2882-496e-b58a-30479a74bdf5",
   "metadata": {},
   "source": [
    "### Dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b438bb-8861-429f-b5ba-288c8007e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(func, n_samples=100):\n",
    "    x = torch.linspace(0, 1, n_samples).unsqueeze(1)\n",
    "    y = func(x)\n",
    "    return x, y\n",
    "\n",
    "def cos_func(x):\n",
    "    return torch.cos(x)\n",
    "\n",
    "def exp_func(x):\n",
    "    return torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3622a-56ba-4e9e-8e0c-76df3c8b8989",
   "metadata": {},
   "source": [
    "## Model application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d8f29-3249-4897-9aac-26970057a532",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc4cd52-b867-4e34-808c-59c99e60c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10000\n",
    "\n",
    "model_cos = MLP(input_size, hidden_size)\n",
    "model_exp = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_cos = optim.Adam(model_cos.parameters(), lr=learning_rate)\n",
    "optimizer_exp = optim.Adam(model_exp.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12309448-29ee-4953-8046-2754b923d71e",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "708d353d-250d-4996-87db-528dc44b9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cos, y_train_cos = generate_data(cos_func, 10000)\n",
    "x_train_exp, y_train_exp = generate_data(exp_func, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e6b77-7c5e-43ee-a29e-cb7ac50db0e4",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55460cd8-b992-4ce7-8370-d43d61afc185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.010741\n",
      "Epoch [200/10000], Loss: 0.002600\n",
      "Epoch [300/10000], Loss: 0.001553\n",
      "Epoch [400/10000], Loss: 0.001421\n",
      "Epoch [500/10000], Loss: 0.001319\n",
      "Epoch [600/10000], Loss: 0.001231\n",
      "Epoch [700/10000], Loss: 0.001154\n",
      "Epoch [800/10000], Loss: 0.001083\n",
      "Epoch [900/10000], Loss: 0.001014\n",
      "Epoch [1000/10000], Loss: 0.000943\n",
      "Epoch [1100/10000], Loss: 0.000867\n",
      "Epoch [1200/10000], Loss: 0.000785\n",
      "Epoch [1300/10000], Loss: 0.000696\n",
      "Epoch [1400/10000], Loss: 0.000602\n",
      "Epoch [1500/10000], Loss: 0.000505\n",
      "Epoch [1600/10000], Loss: 0.000408\n",
      "Epoch [1700/10000], Loss: 0.000317\n",
      "Epoch [1800/10000], Loss: 0.000235\n",
      "Epoch [1900/10000], Loss: 0.000167\n",
      "Epoch [2000/10000], Loss: 0.000113\n",
      "Epoch [2100/10000], Loss: 0.000073\n",
      "Epoch [2200/10000], Loss: 0.000046\n",
      "Epoch [2300/10000], Loss: 0.000029\n",
      "Epoch [2400/10000], Loss: 0.000019\n",
      "Epoch [2500/10000], Loss: 0.000013\n",
      "Epoch [2600/10000], Loss: 0.000010\n",
      "Epoch [2700/10000], Loss: 0.000008\n",
      "Epoch [2800/10000], Loss: 0.000007\n",
      "Epoch [2900/10000], Loss: 0.000007\n",
      "Epoch [3000/10000], Loss: 0.000007\n",
      "Epoch [3100/10000], Loss: 0.000006\n",
      "Epoch [3200/10000], Loss: 0.000006\n",
      "Epoch [3300/10000], Loss: 0.000006\n",
      "Epoch [3400/10000], Loss: 0.000006\n",
      "Epoch [3500/10000], Loss: 0.000006\n",
      "Epoch [3600/10000], Loss: 0.000006\n",
      "Epoch [3700/10000], Loss: 0.000006\n",
      "Epoch [3800/10000], Loss: 0.000006\n",
      "Epoch [3900/10000], Loss: 0.000006\n",
      "Epoch [4000/10000], Loss: 0.000006\n",
      "Epoch [4100/10000], Loss: 0.000006\n",
      "Epoch [4200/10000], Loss: 0.000005\n",
      "Epoch [4300/10000], Loss: 0.000005\n",
      "Epoch [4400/10000], Loss: 0.000005\n",
      "Epoch [4500/10000], Loss: 0.000005\n",
      "Epoch [4600/10000], Loss: 0.000005\n",
      "Epoch [4700/10000], Loss: 0.000005\n",
      "Epoch [4800/10000], Loss: 0.000005\n",
      "Epoch [4900/10000], Loss: 0.000005\n",
      "Epoch [5000/10000], Loss: 0.000005\n",
      "Epoch [5100/10000], Loss: 0.000005\n",
      "Epoch [5200/10000], Loss: 0.000005\n",
      "Epoch [5300/10000], Loss: 0.000005\n",
      "Epoch [5400/10000], Loss: 0.000005\n",
      "Epoch [5500/10000], Loss: 0.000005\n",
      "Epoch [5600/10000], Loss: 0.000005\n",
      "Epoch [5700/10000], Loss: 0.000005\n",
      "Epoch [5800/10000], Loss: 0.000005\n",
      "Epoch [5900/10000], Loss: 0.000005\n",
      "Epoch [6000/10000], Loss: 0.000005\n",
      "Epoch [6100/10000], Loss: 0.000005\n",
      "Epoch [6200/10000], Loss: 0.000004\n",
      "Epoch [6300/10000], Loss: 0.000004\n",
      "Epoch [6400/10000], Loss: 0.000004\n",
      "Epoch [6500/10000], Loss: 0.000004\n",
      "Epoch [6600/10000], Loss: 0.000004\n",
      "Epoch [6700/10000], Loss: 0.000004\n",
      "Epoch [6800/10000], Loss: 0.000005\n",
      "Epoch [6900/10000], Loss: 0.000004\n",
      "Epoch [7000/10000], Loss: 0.000005\n",
      "Epoch [7100/10000], Loss: 0.000004\n",
      "Epoch [7200/10000], Loss: 0.000011\n",
      "Epoch [7300/10000], Loss: 0.000004\n",
      "Epoch [7400/10000], Loss: 0.000004\n",
      "Epoch [7500/10000], Loss: 0.000004\n",
      "Epoch [7600/10000], Loss: 0.000004\n",
      "Epoch [7700/10000], Loss: 0.000013\n",
      "Epoch [7800/10000], Loss: 0.000004\n",
      "Epoch [7900/10000], Loss: 0.000004\n",
      "Epoch [8000/10000], Loss: 0.000004\n",
      "Epoch [8100/10000], Loss: 0.000004\n",
      "Epoch [8200/10000], Loss: 0.000007\n",
      "Epoch [8300/10000], Loss: 0.000003\n",
      "Epoch [8400/10000], Loss: 0.000003\n",
      "Epoch [8500/10000], Loss: 0.000003\n",
      "Epoch [8600/10000], Loss: 0.000003\n",
      "Epoch [8700/10000], Loss: 0.000003\n",
      "Epoch [8800/10000], Loss: 0.000003\n",
      "Epoch [8900/10000], Loss: 0.000003\n",
      "Epoch [9000/10000], Loss: 0.000003\n",
      "Epoch [9100/10000], Loss: 0.000003\n",
      "Epoch [9200/10000], Loss: 0.000003\n",
      "Epoch [9300/10000], Loss: 0.000007\n",
      "Epoch [9400/10000], Loss: 0.000003\n",
      "Epoch [9500/10000], Loss: 0.000003\n",
      "Epoch [9600/10000], Loss: 0.000008\n",
      "Epoch [9700/10000], Loss: 0.000003\n",
      "Epoch [9800/10000], Loss: 0.000003\n",
      "Epoch [9900/10000], Loss: 0.000007\n",
      "Epoch [10000/10000], Loss: 0.000003\n"
     ]
    }
   ],
   "source": [
    "train_model(model_cos, criterion, optimizer_cos, x_train_cos, y_train_cos, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d910223-f12d-44a3-9b43-4b1391df5dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.113125\n",
      "Epoch [200/10000], Loss: 0.053437\n",
      "Epoch [300/10000], Loss: 0.019245\n",
      "Epoch [400/10000], Loss: 0.007358\n",
      "Epoch [500/10000], Loss: 0.005034\n",
      "Epoch [600/10000], Loss: 0.004415\n",
      "Epoch [700/10000], Loss: 0.003967\n",
      "Epoch [800/10000], Loss: 0.003570\n",
      "Epoch [900/10000], Loss: 0.003214\n",
      "Epoch [1000/10000], Loss: 0.002893\n",
      "Epoch [1100/10000], Loss: 0.002599\n",
      "Epoch [1200/10000], Loss: 0.002328\n",
      "Epoch [1300/10000], Loss: 0.002077\n",
      "Epoch [1400/10000], Loss: 0.001843\n",
      "Epoch [1500/10000], Loss: 0.001624\n",
      "Epoch [1600/10000], Loss: 0.001420\n",
      "Epoch [1700/10000], Loss: 0.001231\n",
      "Epoch [1800/10000], Loss: 0.001056\n",
      "Epoch [1900/10000], Loss: 0.000895\n",
      "Epoch [2000/10000], Loss: 0.000750\n",
      "Epoch [2100/10000], Loss: 0.000620\n",
      "Epoch [2200/10000], Loss: 0.000506\n",
      "Epoch [2300/10000], Loss: 0.000407\n",
      "Epoch [2400/10000], Loss: 0.000324\n",
      "Epoch [2500/10000], Loss: 0.000256\n",
      "Epoch [2600/10000], Loss: 0.000200\n",
      "Epoch [2700/10000], Loss: 0.000157\n",
      "Epoch [2800/10000], Loss: 0.000123\n",
      "Epoch [2900/10000], Loss: 0.000098\n",
      "Epoch [3000/10000], Loss: 0.000079\n",
      "Epoch [3100/10000], Loss: 0.000065\n",
      "Epoch [3200/10000], Loss: 0.000055\n",
      "Epoch [3300/10000], Loss: 0.000047\n",
      "Epoch [3400/10000], Loss: 0.000042\n",
      "Epoch [3500/10000], Loss: 0.000037\n",
      "Epoch [3600/10000], Loss: 0.000034\n",
      "Epoch [3700/10000], Loss: 0.000030\n",
      "Epoch [3800/10000], Loss: 0.000028\n",
      "Epoch [3900/10000], Loss: 0.000025\n",
      "Epoch [4000/10000], Loss: 0.000023\n",
      "Epoch [4100/10000], Loss: 0.000021\n",
      "Epoch [4200/10000], Loss: 0.000020\n",
      "Epoch [4300/10000], Loss: 0.000018\n",
      "Epoch [4400/10000], Loss: 0.000017\n",
      "Epoch [4500/10000], Loss: 0.000015\n",
      "Epoch [4600/10000], Loss: 0.000014\n",
      "Epoch [4700/10000], Loss: 0.000013\n",
      "Epoch [4800/10000], Loss: 0.000012\n",
      "Epoch [4900/10000], Loss: 0.000011\n",
      "Epoch [5000/10000], Loss: 0.000010\n",
      "Epoch [5100/10000], Loss: 0.000010\n",
      "Epoch [5200/10000], Loss: 0.000009\n",
      "Epoch [5300/10000], Loss: 0.000008\n",
      "Epoch [5400/10000], Loss: 0.000008\n",
      "Epoch [5500/10000], Loss: 0.000007\n",
      "Epoch [5600/10000], Loss: 0.000006\n",
      "Epoch [5700/10000], Loss: 0.000006\n",
      "Epoch [5800/10000], Loss: 0.000005\n",
      "Epoch [5900/10000], Loss: 0.000005\n",
      "Epoch [6000/10000], Loss: 0.000005\n",
      "Epoch [6100/10000], Loss: 0.000004\n",
      "Epoch [6200/10000], Loss: 0.000004\n",
      "Epoch [6300/10000], Loss: 0.000004\n",
      "Epoch [6400/10000], Loss: 0.000003\n",
      "Epoch [6500/10000], Loss: 0.000003\n",
      "Epoch [6600/10000], Loss: 0.000003\n",
      "Epoch [6700/10000], Loss: 0.000003\n",
      "Epoch [6800/10000], Loss: 0.000002\n",
      "Epoch [6900/10000], Loss: 0.000002\n",
      "Epoch [7000/10000], Loss: 0.000002\n",
      "Epoch [7100/10000], Loss: 0.000002\n",
      "Epoch [7200/10000], Loss: 0.000002\n",
      "Epoch [7300/10000], Loss: 0.000002\n",
      "Epoch [7400/10000], Loss: 0.000002\n",
      "Epoch [7500/10000], Loss: 0.000002\n",
      "Epoch [7600/10000], Loss: 0.000001\n",
      "Epoch [7700/10000], Loss: 0.000001\n",
      "Epoch [7800/10000], Loss: 0.000001\n",
      "Epoch [7900/10000], Loss: 0.000001\n",
      "Epoch [8000/10000], Loss: 0.000001\n",
      "Epoch [8100/10000], Loss: 0.000001\n",
      "Epoch [8200/10000], Loss: 0.000001\n",
      "Epoch [8300/10000], Loss: 0.000001\n",
      "Epoch [8400/10000], Loss: 0.000001\n",
      "Epoch [8500/10000], Loss: 0.000001\n",
      "Epoch [8600/10000], Loss: 0.000001\n",
      "Epoch [8700/10000], Loss: 0.000001\n",
      "Epoch [8800/10000], Loss: 0.000001\n",
      "Epoch [8900/10000], Loss: 0.000001\n",
      "Epoch [9000/10000], Loss: 0.000001\n",
      "Epoch [9100/10000], Loss: 0.000001\n",
      "Epoch [9200/10000], Loss: 0.000001\n",
      "Epoch [9300/10000], Loss: 0.000001\n",
      "Epoch [9400/10000], Loss: 0.000002\n",
      "Epoch [9500/10000], Loss: 0.000001\n",
      "Epoch [9600/10000], Loss: 0.000029\n",
      "Epoch [9700/10000], Loss: 0.000001\n",
      "Epoch [9800/10000], Loss: 0.000001\n",
      "Epoch [9900/10000], Loss: 0.000001\n",
      "Epoch [10000/10000], Loss: 0.000001\n"
     ]
    }
   ],
   "source": [
    "train_model(model_exp, criterion, optimizer_exp, x_train_exp, y_train_exp, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9f25a-6b78-42d6-b07a-317296a54880",
   "metadata": {},
   "source": [
    "### Extractoin of the parameters of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19dce1d3-1b8d-4716-9d14-408de4431a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_params(model):\n",
    "    b1 = model.input_layer.bias.detach().numpy()\n",
    "    weights_w1 = model.input_layer.weight.detach().numpy().flatten()\n",
    "    b2 = model.output_layer.bias.item()\n",
    "    weights_w2 = model.output_layer.weight.detach().numpy().flatten()\n",
    "\n",
    "    return b1, weights_w1, b2, weights_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0576319-05e1-4828-8c2d-e2a57c092162",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_cos, weights_w1_cos, b2_cos, weights_w2_cos = extract_model_params(model_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26596c2e-271f-49ad-ac8a-95942825645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_exp, weights_w1_exp, b2_exp, weights_w2_exp = extract_model_params(model_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3845e2-89b7-4bfa-8d83-789d9f1d57c3",
   "metadata": {},
   "source": [
    "### Integreation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b4b85c-e2f8-400a-be87-f5c63cd7c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "beta = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4afb7e-ba84-4db5-a60b-9f0143c23e6b",
   "metadata": {},
   "source": [
    "### NNI integral calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2a7974-e3f0-4fbb-9c93-5f33614f6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_cos = get_NN_analytical_integral(alpha, beta, b1_cos, b2_cos, weights_w1_cos, weights_w2_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46088489-19e4-4de6-b09e-2676dbb4cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of cos(x) of the trained neural network model is: 0.841461\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of cos(x) of the trained neural network model is: {float(integral_cos):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d13e1e4-36d7-434b-a986-8f0a95f03e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_exp = get_NN_analytical_integral(alpha, beta, b1_exp, b2_exp, weights_w1_exp, weights_w2_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bc036b6-b92e-42d7-acf2-a70ea1c3f71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of exp(x) of the trained neural network model is: 1.718283\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of exp(x) of the trained neural network model is: {float(integral_exp):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48461cd1-49f7-48c7-ac33-9ae65a4143fe",
   "metadata": {},
   "source": [
    "### True integral for comparison\n",
    "\n",
    "$\\int_{\\alpha}^{\\beta} dx\\{cos(x)\\} = sin(\\beta) - sin(\\alpha) $\n",
    "\n",
    "$\\int_{\\alpha}^{\\beta} dx\\{exp(x)\\} = exp(\\beta) - exp(\\alpha) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95abe020-53e7-4ba1-b382-30de9a5398bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_integral_cos = np.sin(beta) - np.sin(alpha)\n",
    "true_integral_exp = np.exp(beta) - np.exp(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "250a1cda-25c1-47d3-9832-f2371acc7932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true cosinus integral is: 0.841471\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true cosinus integral is: {float(true_integral_cos):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14ff1e16-cd4b-48fa-aae4-4a045aa16f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true exponent integral is: 1.718282\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true exponent integral is: {float(true_integral_exp):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e5bfc-1672-4b23-a1f2-cbc47a4276af",
   "metadata": {},
   "source": [
    "## Integration of function 1.1.1:\n",
    "\n",
    "$ \\int_{0}^{1}d\\alpha\\{ \\alpha^a(1 - \\alpha)^b \\}, a = 1, b = 1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22b07380-7149-4749-a8b5-c2a545a3a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 1\n",
    "\n",
    "def alpha_func(alpha):\n",
    "    return alpha ** a * (1 - alpha) ** b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cce6e8d0-7b3c-4adb-8a83-00ea46ad0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alpha = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_alpha = optim.Adam(model_alpha.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15833013-2565-4e6f-9244-9c201607b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_alpha, y_train_alpha = generate_data(alpha_func, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6009851-176e-4a46-a7cf-bf44730155d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.005567\n",
      "Epoch [200/10000], Loss: 0.005509\n",
      "Epoch [300/10000], Loss: 0.005473\n",
      "Epoch [400/10000], Loss: 0.005406\n",
      "Epoch [500/10000], Loss: 0.005250\n",
      "Epoch [600/10000], Loss: 0.004783\n",
      "Epoch [700/10000], Loss: 0.003510\n",
      "Epoch [800/10000], Loss: 0.001313\n",
      "Epoch [900/10000], Loss: 0.000208\n",
      "Epoch [1000/10000], Loss: 0.000111\n",
      "Epoch [1100/10000], Loss: 0.000091\n",
      "Epoch [1200/10000], Loss: 0.000080\n",
      "Epoch [1300/10000], Loss: 0.000072\n",
      "Epoch [1400/10000], Loss: 0.000064\n",
      "Epoch [1500/10000], Loss: 0.000058\n",
      "Epoch [1600/10000], Loss: 0.000051\n",
      "Epoch [1700/10000], Loss: 0.000045\n",
      "Epoch [1800/10000], Loss: 0.000039\n",
      "Epoch [1900/10000], Loss: 0.000034\n",
      "Epoch [2000/10000], Loss: 0.000029\n",
      "Epoch [2100/10000], Loss: 0.000025\n",
      "Epoch [2200/10000], Loss: 0.000021\n",
      "Epoch [2300/10000], Loss: 0.000017\n",
      "Epoch [2400/10000], Loss: 0.000014\n",
      "Epoch [2500/10000], Loss: 0.000011\n",
      "Epoch [2600/10000], Loss: 0.000009\n",
      "Epoch [2700/10000], Loss: 0.000007\n",
      "Epoch [2800/10000], Loss: 0.000006\n",
      "Epoch [2900/10000], Loss: 0.000004\n",
      "Epoch [3000/10000], Loss: 0.000003\n",
      "Epoch [3100/10000], Loss: 0.000003\n",
      "Epoch [3200/10000], Loss: 0.000002\n",
      "Epoch [3300/10000], Loss: 0.000002\n",
      "Epoch [3400/10000], Loss: 0.000001\n",
      "Epoch [3500/10000], Loss: 0.000001\n",
      "Epoch [3600/10000], Loss: 0.000001\n",
      "Epoch [3700/10000], Loss: 0.000004\n",
      "Epoch [3800/10000], Loss: 0.000001\n",
      "Epoch [3900/10000], Loss: 0.000001\n",
      "Epoch [4000/10000], Loss: 0.000001\n",
      "Epoch [4100/10000], Loss: 0.000001\n",
      "Epoch [4200/10000], Loss: 0.000001\n",
      "Epoch [4300/10000], Loss: 0.000001\n",
      "Epoch [4400/10000], Loss: 0.000001\n",
      "Epoch [4500/10000], Loss: 0.000001\n",
      "Epoch [4600/10000], Loss: 0.000001\n",
      "Epoch [4700/10000], Loss: 0.000001\n",
      "Epoch [4800/10000], Loss: 0.000000\n",
      "Epoch [4900/10000], Loss: 0.000000\n",
      "Epoch [5000/10000], Loss: 0.000001\n",
      "Epoch [5100/10000], Loss: 0.000000\n",
      "Epoch [5200/10000], Loss: 0.000001\n",
      "Epoch [5300/10000], Loss: 0.000000\n",
      "Epoch [5400/10000], Loss: 0.000000\n",
      "Epoch [5500/10000], Loss: 0.000030\n",
      "Epoch [5600/10000], Loss: 0.000000\n",
      "Epoch [5700/10000], Loss: 0.000000\n",
      "Epoch [5800/10000], Loss: 0.000002\n",
      "Epoch [5900/10000], Loss: 0.000000\n",
      "Epoch [6000/10000], Loss: 0.000000\n",
      "Epoch [6100/10000], Loss: 0.000003\n",
      "Epoch [6200/10000], Loss: 0.000000\n",
      "Epoch [6300/10000], Loss: 0.000000\n",
      "Epoch [6400/10000], Loss: 0.000000\n",
      "Epoch [6500/10000], Loss: 0.000001\n",
      "Epoch [6600/10000], Loss: 0.000000\n",
      "Epoch [6700/10000], Loss: 0.000000\n",
      "Epoch [6800/10000], Loss: 0.000000\n",
      "Epoch [6900/10000], Loss: 0.000000\n",
      "Epoch [7000/10000], Loss: 0.000000\n",
      "Epoch [7100/10000], Loss: 0.000013\n",
      "Epoch [7200/10000], Loss: 0.000000\n",
      "Epoch [7300/10000], Loss: 0.000000\n",
      "Epoch [7400/10000], Loss: 0.000000\n",
      "Epoch [7500/10000], Loss: 0.000126\n",
      "Epoch [7600/10000], Loss: 0.000000\n",
      "Epoch [7700/10000], Loss: 0.000000\n",
      "Epoch [7800/10000], Loss: 0.000025\n",
      "Epoch [7900/10000], Loss: 0.000000\n",
      "Epoch [8000/10000], Loss: 0.000000\n",
      "Epoch [8100/10000], Loss: 0.000004\n",
      "Epoch [8200/10000], Loss: 0.000000\n",
      "Epoch [8300/10000], Loss: 0.000000\n",
      "Epoch [8400/10000], Loss: 0.000000\n",
      "Epoch [8500/10000], Loss: 0.000000\n",
      "Epoch [8600/10000], Loss: 0.000000\n",
      "Epoch [8700/10000], Loss: 0.000000\n",
      "Epoch [8800/10000], Loss: 0.000000\n",
      "Epoch [8900/10000], Loss: 0.000003\n",
      "Epoch [9000/10000], Loss: 0.000000\n",
      "Epoch [9100/10000], Loss: 0.000000\n",
      "Epoch [9200/10000], Loss: 0.000001\n",
      "Epoch [9300/10000], Loss: 0.000000\n",
      "Epoch [9400/10000], Loss: 0.000000\n",
      "Epoch [9500/10000], Loss: 0.000000\n",
      "Epoch [9600/10000], Loss: 0.000000\n",
      "Epoch [9700/10000], Loss: 0.000000\n",
      "Epoch [9800/10000], Loss: 0.000000\n",
      "Epoch [9900/10000], Loss: 0.000000\n",
      "Epoch [10000/10000], Loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "train_model(model_alpha, criterion, optimizer_alpha, x_train_alpha, y_train_alpha, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59e4d09b-8241-4904-9354-12c2b7f7d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_alpha, weights_w1_alpha, b2_alpha, weights_w2_alpha = extract_model_params(model_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a22f3a12-6d5e-4e24-9739-bfe2b240a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_alpha = get_NN_analytical_integral(alpha, beta, b1_alpha, b2_alpha, weights_w1_alpha, weights_w2_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f10235fe-234e-4ffd-9ad4-ab90b3ab1539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of exp(x) of the trained neural network model is: 0.166672\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of exp(x) of the trained neural network model is: {float(integral_alpha):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ee0cb3-3321-43c2-b5d0-2a7efdf37f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_integral_alpha = (1/2 - 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29cf3a2d-912d-4df0-9d77-8f69da76cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true cosinus integral is: 0.166667\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true cosinus integral is: {float(true_integral_alpha):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a33bcb-40a0-40c1-b4b3-b6e6629c79f6",
   "metadata": {},
   "source": [
    "## Integration of function 1.1.2:\n",
    "\n",
    "$ \\int_{0}^{1}d\\alpha\\{ \\alpha^a(1 - \\alpha)^b \\}, a = 0, b = 1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7aa7439-377d-4b5d-b7d2-53d1303ed0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4fdaea7-4fd1-4b75-802a-6ca040985214",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_alpha_2 = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_alpha = optim.Adam(model_alpha_2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0b9aec8-d438-4406-9deb-b70d463aaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_alpha_2, y_train_alpha_2 = generate_data(alpha_func, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7c58dbc-85c4-4fed-8fff-794d29b7ed16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.040663\n",
      "Epoch [200/10000], Loss: 0.001378\n",
      "Epoch [300/10000], Loss: 0.000214\n",
      "Epoch [400/10000], Loss: 0.000154\n",
      "Epoch [500/10000], Loss: 0.000110\n",
      "Epoch [600/10000], Loss: 0.000080\n",
      "Epoch [700/10000], Loss: 0.000059\n",
      "Epoch [800/10000], Loss: 0.000045\n",
      "Epoch [900/10000], Loss: 0.000035\n",
      "Epoch [1000/10000], Loss: 0.000028\n",
      "Epoch [1100/10000], Loss: 0.000024\n",
      "Epoch [1200/10000], Loss: 0.000020\n",
      "Epoch [1300/10000], Loss: 0.000018\n",
      "Epoch [1400/10000], Loss: 0.000016\n",
      "Epoch [1500/10000], Loss: 0.000015\n",
      "Epoch [1600/10000], Loss: 0.000014\n",
      "Epoch [1700/10000], Loss: 0.000013\n",
      "Epoch [1800/10000], Loss: 0.000012\n",
      "Epoch [1900/10000], Loss: 0.000012\n",
      "Epoch [2000/10000], Loss: 0.000011\n",
      "Epoch [2100/10000], Loss: 0.000010\n",
      "Epoch [2200/10000], Loss: 0.000010\n",
      "Epoch [2300/10000], Loss: 0.000009\n",
      "Epoch [2400/10000], Loss: 0.000009\n",
      "Epoch [2500/10000], Loss: 0.000008\n",
      "Epoch [2600/10000], Loss: 0.000008\n",
      "Epoch [2700/10000], Loss: 0.000008\n",
      "Epoch [2800/10000], Loss: 0.000007\n",
      "Epoch [2900/10000], Loss: 0.000007\n",
      "Epoch [3000/10000], Loss: 0.000007\n",
      "Epoch [3100/10000], Loss: 0.000006\n",
      "Epoch [3200/10000], Loss: 0.000006\n",
      "Epoch [3300/10000], Loss: 0.000006\n",
      "Epoch [3400/10000], Loss: 0.000005\n",
      "Epoch [3500/10000], Loss: 0.000005\n",
      "Epoch [3600/10000], Loss: 0.000005\n",
      "Epoch [3700/10000], Loss: 0.000005\n",
      "Epoch [3800/10000], Loss: 0.000004\n",
      "Epoch [3900/10000], Loss: 0.000004\n",
      "Epoch [4000/10000], Loss: 0.000004\n",
      "Epoch [4100/10000], Loss: 0.000004\n",
      "Epoch [4200/10000], Loss: 0.000004\n",
      "Epoch [4300/10000], Loss: 0.000003\n",
      "Epoch [4400/10000], Loss: 0.000003\n",
      "Epoch [4500/10000], Loss: 0.000003\n",
      "Epoch [4600/10000], Loss: 0.000003\n",
      "Epoch [4700/10000], Loss: 0.000003\n",
      "Epoch [4800/10000], Loss: 0.000003\n",
      "Epoch [4900/10000], Loss: 0.000002\n",
      "Epoch [5000/10000], Loss: 0.000002\n",
      "Epoch [5100/10000], Loss: 0.000002\n",
      "Epoch [5200/10000], Loss: 0.000002\n",
      "Epoch [5300/10000], Loss: 0.000002\n",
      "Epoch [5400/10000], Loss: 0.000002\n",
      "Epoch [5500/10000], Loss: 0.000002\n",
      "Epoch [5600/10000], Loss: 0.000002\n",
      "Epoch [5700/10000], Loss: 0.000001\n",
      "Epoch [5800/10000], Loss: 0.000001\n",
      "Epoch [5900/10000], Loss: 0.000001\n",
      "Epoch [6000/10000], Loss: 0.000001\n",
      "Epoch [6100/10000], Loss: 0.000001\n",
      "Epoch [6200/10000], Loss: 0.000004\n",
      "Epoch [6300/10000], Loss: 0.000001\n",
      "Epoch [6400/10000], Loss: 0.000001\n",
      "Epoch [6500/10000], Loss: 0.000001\n",
      "Epoch [6600/10000], Loss: 0.000001\n",
      "Epoch [6700/10000], Loss: 0.000010\n",
      "Epoch [6800/10000], Loss: 0.000001\n",
      "Epoch [6900/10000], Loss: 0.000001\n",
      "Epoch [7000/10000], Loss: 0.000001\n",
      "Epoch [7100/10000], Loss: 0.000001\n",
      "Epoch [7200/10000], Loss: 0.000001\n",
      "Epoch [7300/10000], Loss: 0.000015\n",
      "Epoch [7400/10000], Loss: 0.000001\n",
      "Epoch [7500/10000], Loss: 0.000000\n",
      "Epoch [7600/10000], Loss: 0.000016\n",
      "Epoch [7700/10000], Loss: 0.000000\n",
      "Epoch [7800/10000], Loss: 0.000000\n",
      "Epoch [7900/10000], Loss: 0.000002\n",
      "Epoch [8000/10000], Loss: 0.000000\n",
      "Epoch [8100/10000], Loss: 0.000000\n",
      "Epoch [8200/10000], Loss: 0.000000\n",
      "Epoch [8300/10000], Loss: 0.000000\n",
      "Epoch [8400/10000], Loss: 0.000109\n",
      "Epoch [8500/10000], Loss: 0.000000\n",
      "Epoch [8600/10000], Loss: 0.000000\n",
      "Epoch [8700/10000], Loss: 0.000006\n",
      "Epoch [8800/10000], Loss: 0.000000\n",
      "Epoch [8900/10000], Loss: 0.000000\n",
      "Epoch [9000/10000], Loss: 0.000001\n",
      "Epoch [9100/10000], Loss: 0.000000\n",
      "Epoch [9200/10000], Loss: 0.000000\n",
      "Epoch [9300/10000], Loss: 0.000001\n",
      "Epoch [9400/10000], Loss: 0.000000\n",
      "Epoch [9500/10000], Loss: 0.000000\n",
      "Epoch [9600/10000], Loss: 0.000000\n",
      "Epoch [9700/10000], Loss: 0.000000\n",
      "Epoch [9800/10000], Loss: 0.000000\n",
      "Epoch [9900/10000], Loss: 0.000001\n",
      "Epoch [10000/10000], Loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "train_model(model_alpha_2, criterion, optimizer_alpha, x_train_alpha_2, y_train_alpha_2, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4310ca0b-4fb2-48dc-bda7-36858d7c8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_alpha_2, weights_w1_alpha_2, b2_alpha_2, weights_w2_alpha_2 = extract_model_params(model_alpha_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538defd6-2c7d-4dbc-9827-e7131bbe819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_alpha_2 = get_NN_analytical_integral(alpha, beta, b1_alpha_2, b2_alpha_2, weights_w1_alpha_2, weights_w2_alpha_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8719326f-d598-4f79-bb24-748183107d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of alpha^a(1 - alpha)^b of the trained neural network model is: 0.499994\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of alpha^a(1 - alpha)^b of the trained neural network model is: {float(integral_alpha_2):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df5e8b2b-b9c3-4a64-a5ce-7c3ed5b45535",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_integral_alpha_2 = (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44aa66b2-dd70-4eca-9073-a2a50a9848c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true cosinus integral is: 0.500000\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true cosinus integral is: {float(true_integral_alpha_2):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae31417d-3c4a-42a7-b08e-026a89e7c3f1",
   "metadata": {},
   "source": [
    "## Integration of function 1.1.3:\n",
    "\n",
    "$ \\int_{0}^{1}d\\alpha\\{ \\alpha^a(1 - \\alpha)^b \\}, a = 1, b = 0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9649827-b91b-4106-9e0e-108ca4990801",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18355537-fcd0-417e-86ed-1531f80a7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alpha_3 = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_alpha = optim.Adam(model_alpha_3.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df13ebc4-a86d-4807-8ed0-a3199cae8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_alpha_3, y_train_alpha_3 = generate_data(alpha_func, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f03a18e5-1af0-4b9a-8713-953d9812ffdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.000017\n",
      "Epoch [200/10000], Loss: 0.000013\n",
      "Epoch [300/10000], Loss: 0.000010\n",
      "Epoch [400/10000], Loss: 0.000007\n",
      "Epoch [500/10000], Loss: 0.000005\n",
      "Epoch [600/10000], Loss: 0.000004\n",
      "Epoch [700/10000], Loss: 0.000004\n",
      "Epoch [800/10000], Loss: 0.000003\n",
      "Epoch [900/10000], Loss: 0.000003\n",
      "Epoch [1000/10000], Loss: 0.000003\n",
      "Epoch [1100/10000], Loss: 0.000003\n",
      "Epoch [1200/10000], Loss: 0.000003\n",
      "Epoch [1300/10000], Loss: 0.000003\n",
      "Epoch [1400/10000], Loss: 0.000003\n",
      "Epoch [1500/10000], Loss: 0.000003\n",
      "Epoch [1600/10000], Loss: 0.000004\n",
      "Epoch [1700/10000], Loss: 0.000003\n",
      "Epoch [1800/10000], Loss: 0.000015\n",
      "Epoch [1900/10000], Loss: 0.000003\n",
      "Epoch [2000/10000], Loss: 0.000003\n",
      "Epoch [2100/10000], Loss: 0.000016\n",
      "Epoch [2200/10000], Loss: 0.000003\n",
      "Epoch [2300/10000], Loss: 0.000002\n",
      "Epoch [2400/10000], Loss: 0.000002\n",
      "Epoch [2500/10000], Loss: 0.000002\n",
      "Epoch [2600/10000], Loss: 0.000002\n",
      "Epoch [2700/10000], Loss: 0.000002\n",
      "Epoch [2800/10000], Loss: 0.000002\n",
      "Epoch [2900/10000], Loss: 0.000002\n",
      "Epoch [3000/10000], Loss: 0.000002\n",
      "Epoch [3100/10000], Loss: 0.000002\n",
      "Epoch [3200/10000], Loss: 0.000002\n",
      "Epoch [3300/10000], Loss: 0.000002\n",
      "Epoch [3400/10000], Loss: 0.000002\n",
      "Epoch [3500/10000], Loss: 0.000002\n",
      "Epoch [3600/10000], Loss: 0.000004\n",
      "Epoch [3700/10000], Loss: 0.000002\n",
      "Epoch [3800/10000], Loss: 0.000002\n",
      "Epoch [3900/10000], Loss: 0.000006\n",
      "Epoch [4000/10000], Loss: 0.000002\n",
      "Epoch [4100/10000], Loss: 0.000002\n",
      "Epoch [4200/10000], Loss: 0.000002\n",
      "Epoch [4300/10000], Loss: 0.000002\n",
      "Epoch [4400/10000], Loss: 0.000002\n",
      "Epoch [4500/10000], Loss: 0.000004\n",
      "Epoch [4600/10000], Loss: 0.000002\n",
      "Epoch [4700/10000], Loss: 0.000002\n",
      "Epoch [4800/10000], Loss: 0.000002\n",
      "Epoch [4900/10000], Loss: 0.000002\n",
      "Epoch [5000/10000], Loss: 0.000034\n",
      "Epoch [5100/10000], Loss: 0.000002\n",
      "Epoch [5200/10000], Loss: 0.000002\n",
      "Epoch [5300/10000], Loss: 0.000003\n",
      "Epoch [5400/10000], Loss: 0.000002\n",
      "Epoch [5500/10000], Loss: 0.000002\n",
      "Epoch [5600/10000], Loss: 0.000002\n",
      "Epoch [5700/10000], Loss: 0.000002\n",
      "Epoch [5800/10000], Loss: 0.000002\n",
      "Epoch [5900/10000], Loss: 0.000005\n",
      "Epoch [6000/10000], Loss: 0.000002\n",
      "Epoch [6100/10000], Loss: 0.000002\n",
      "Epoch [6200/10000], Loss: 0.000002\n",
      "Epoch [6300/10000], Loss: 0.000002\n",
      "Epoch [6400/10000], Loss: 0.000002\n",
      "Epoch [6500/10000], Loss: 0.000002\n",
      "Epoch [6600/10000], Loss: 0.000002\n",
      "Epoch [6700/10000], Loss: 0.000002\n",
      "Epoch [6800/10000], Loss: 0.000003\n",
      "Epoch [6900/10000], Loss: 0.000002\n",
      "Epoch [7000/10000], Loss: 0.000002\n",
      "Epoch [7100/10000], Loss: 0.000002\n",
      "Epoch [7200/10000], Loss: 0.000002\n",
      "Epoch [7300/10000], Loss: 0.000002\n",
      "Epoch [7400/10000], Loss: 0.000002\n",
      "Epoch [7500/10000], Loss: 0.000002\n",
      "Epoch [7600/10000], Loss: 0.000072\n",
      "Epoch [7700/10000], Loss: 0.000002\n",
      "Epoch [7800/10000], Loss: 0.000002\n",
      "Epoch [7900/10000], Loss: 0.000015\n",
      "Epoch [8000/10000], Loss: 0.000002\n",
      "Epoch [8100/10000], Loss: 0.000002\n",
      "Epoch [8200/10000], Loss: 0.000002\n",
      "Epoch [8300/10000], Loss: 0.000002\n",
      "Epoch [8400/10000], Loss: 0.000001\n",
      "Epoch [8500/10000], Loss: 0.000002\n",
      "Epoch [8600/10000], Loss: 0.000001\n",
      "Epoch [8700/10000], Loss: 0.000001\n",
      "Epoch [8800/10000], Loss: 0.000003\n",
      "Epoch [8900/10000], Loss: 0.000001\n",
      "Epoch [9000/10000], Loss: 0.000001\n",
      "Epoch [9100/10000], Loss: 0.000001\n",
      "Epoch [9200/10000], Loss: 0.000001\n",
      "Epoch [9300/10000], Loss: 0.000001\n",
      "Epoch [9400/10000], Loss: 0.000001\n",
      "Epoch [9500/10000], Loss: 0.000001\n",
      "Epoch [9600/10000], Loss: 0.000001\n",
      "Epoch [9700/10000], Loss: 0.000001\n",
      "Epoch [9800/10000], Loss: 0.000001\n",
      "Epoch [9900/10000], Loss: 0.000031\n",
      "Epoch [10000/10000], Loss: 0.000001\n"
     ]
    }
   ],
   "source": [
    "train_model(model_alpha_3, criterion, optimizer_alpha, x_train_alpha_3, y_train_alpha_3, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ced919e-cfdc-4498-9333-9a4f37c596c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_alpha_3, weights_w1_alpha_3, b2_alpha_3, weights_w2_alpha_3 = extract_model_params(model_alpha_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21dbc83a-17f3-4e1a-9632-02de2876ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_alpha_3 = get_NN_analytical_integral(alpha, beta, b1_alpha_3, b2_alpha_3, weights_w1_alpha_3, weights_w2_alpha_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "daa13908-aacd-4283-8d47-a6be6828b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of alpha^a(1 - alpha)^b of the trained neural network model is: 0.500023\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of alpha^a(1 - alpha)^b of the trained neural network model is: {float(integral_alpha_3):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fb54fde-4084-4093-81ab-7394e40043bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_integral_alpha_3 = (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0cb80f36-f74f-4fee-b7d9-2154203e149c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true cosinus integral is: 0.500000\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true cosinus integral is: {float(true_integral_alpha_3):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
