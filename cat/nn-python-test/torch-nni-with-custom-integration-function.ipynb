{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46f1260-cb49-41b5-b222-cf7514ebfa26",
   "metadata": {},
   "source": [
    "# Torch Neural Network Integration with custom integration function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f332b-fe2b-4c53-9d70-4d9eba09061c",
   "metadata": {},
   "source": [
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b44e85b-2955-4da7-8784-cf36ac153fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from mpmath import polylog, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cec9f5-6de3-4867-b818-e8152ad3d11a",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a15a0-1572-4e62-9d31-df1b75276039",
   "metadata": {},
   "source": [
    "### Neural Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27041c02-f514-4492-a4e4-18a308afe158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden_layer = nn.Sigmoid()\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03023775-84b5-4ac0-8ef4-b02310909287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, x_train, y_train, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        predictions = model(x_train)\n",
    "        loss = criterion(predictions, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc435e3-0a6f-4374-a5f9-614d11de8b1b",
   "metadata": {},
   "source": [
    "### NN custom integration function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c882d6-f634-4c49-a568-603bb24595fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NN_analytical_integral(alpha, beta, b1, b2, weights_w1, weights_w2):\n",
    "\n",
    "    def compute_phi_j(b1_j, w1_j, alpha, beta):\n",
    "        term_alpha = polylog(1, -exp(-b1_j - w1_j * alpha))\n",
    "        term_beta = polylog(1, -exp(-b1_j - w1_j * beta))\n",
    "        return term_alpha - term_beta\n",
    "\n",
    "    integral_sum = 0\n",
    "    for w2, w1, b1_j in zip(weights_w2, weights_w1, b1):\n",
    "        phi_j = compute_phi_j(b1_j, w1, alpha, beta)\n",
    "        integral_sum += w2 * ((beta - alpha) + phi_j / w1)\n",
    "    \n",
    "    return b2 * (beta - alpha) + integral_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad98c2e-2882-496e-b58a-30479a74bdf5",
   "metadata": {},
   "source": [
    "### Dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b438bb-8861-429f-b5ba-288c8007e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(func, n_samples=100):\n",
    "    x = torch.linspace(0, 1, n_samples).unsqueeze(1)\n",
    "    y = func(x)\n",
    "    return x, y\n",
    "\n",
    "def cos_func(x):\n",
    "    return torch.cos(x)\n",
    "\n",
    "def exp_func(x):\n",
    "    return torch.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3622a-56ba-4e9e-8e0c-76df3c8b8989",
   "metadata": {},
   "source": [
    "## Model application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d8f29-3249-4897-9aac-26970057a532",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc4cd52-b867-4e34-808c-59c99e60c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10000\n",
    "\n",
    "model_cos = MLP(input_size, hidden_size)\n",
    "model_exp = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_cos = optim.Adam(model_cos.parameters(), lr=learning_rate)\n",
    "optimizer_exp = optim.Adam(model_exp.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12309448-29ee-4953-8046-2754b923d71e",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "708d353d-250d-4996-87db-528dc44b9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cos, y_train_cos = generate_data(cos_func, 10000)\n",
    "x_train_exp, y_train_exp = generate_data(exp_func, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e6b77-7c5e-43ee-a29e-cb7ac50db0e4",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55460cd8-b992-4ce7-8370-d43d61afc185",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.018443\n",
      "Epoch [200/10000], Loss: 0.004171\n",
      "Epoch [300/10000], Loss: 0.001755\n",
      "Epoch [400/10000], Loss: 0.001576\n",
      "Epoch [500/10000], Loss: 0.001472\n",
      "Epoch [600/10000], Loss: 0.001381\n",
      "Epoch [700/10000], Loss: 0.001305\n",
      "Epoch [800/10000], Loss: 0.001241\n",
      "Epoch [900/10000], Loss: 0.001186\n",
      "Epoch [1000/10000], Loss: 0.001138\n",
      "Epoch [1100/10000], Loss: 0.001094\n",
      "Epoch [1200/10000], Loss: 0.001054\n",
      "Epoch [1300/10000], Loss: 0.001015\n",
      "Epoch [1400/10000], Loss: 0.000975\n",
      "Epoch [1500/10000], Loss: 0.000934\n",
      "Epoch [1600/10000], Loss: 0.000890\n",
      "Epoch [1700/10000], Loss: 0.000841\n",
      "Epoch [1800/10000], Loss: 0.000788\n",
      "Epoch [1900/10000], Loss: 0.000728\n",
      "Epoch [2000/10000], Loss: 0.000660\n",
      "Epoch [2100/10000], Loss: 0.000586\n",
      "Epoch [2200/10000], Loss: 0.000506\n",
      "Epoch [2300/10000], Loss: 0.000421\n",
      "Epoch [2400/10000], Loss: 0.000336\n",
      "Epoch [2500/10000], Loss: 0.000255\n",
      "Epoch [2600/10000], Loss: 0.000182\n",
      "Epoch [2700/10000], Loss: 0.000122\n",
      "Epoch [2800/10000], Loss: 0.000077\n",
      "Epoch [2900/10000], Loss: 0.000045\n",
      "Epoch [3000/10000], Loss: 0.000025\n",
      "Epoch [3100/10000], Loss: 0.000014\n",
      "Epoch [3200/10000], Loss: 0.000008\n",
      "Epoch [3300/10000], Loss: 0.000006\n",
      "Epoch [3400/10000], Loss: 0.000004\n",
      "Epoch [3500/10000], Loss: 0.000004\n",
      "Epoch [3600/10000], Loss: 0.000004\n",
      "Epoch [3700/10000], Loss: 0.000003\n",
      "Epoch [3800/10000], Loss: 0.000003\n",
      "Epoch [3900/10000], Loss: 0.000003\n",
      "Epoch [4000/10000], Loss: 0.000003\n",
      "Epoch [4100/10000], Loss: 0.000003\n",
      "Epoch [4200/10000], Loss: 0.000003\n",
      "Epoch [4300/10000], Loss: 0.000003\n",
      "Epoch [4400/10000], Loss: 0.000003\n",
      "Epoch [4500/10000], Loss: 0.000003\n",
      "Epoch [4600/10000], Loss: 0.000003\n",
      "Epoch [4700/10000], Loss: 0.000003\n",
      "Epoch [4800/10000], Loss: 0.000003\n",
      "Epoch [4900/10000], Loss: 0.000003\n",
      "Epoch [5000/10000], Loss: 0.000003\n",
      "Epoch [5100/10000], Loss: 0.000003\n",
      "Epoch [5200/10000], Loss: 0.000003\n",
      "Epoch [5300/10000], Loss: 0.000003\n",
      "Epoch [5400/10000], Loss: 0.000003\n",
      "Epoch [5500/10000], Loss: 0.000003\n",
      "Epoch [5600/10000], Loss: 0.000003\n",
      "Epoch [5700/10000], Loss: 0.000003\n",
      "Epoch [5800/10000], Loss: 0.000003\n",
      "Epoch [5900/10000], Loss: 0.000003\n",
      "Epoch [6000/10000], Loss: 0.000003\n",
      "Epoch [6100/10000], Loss: 0.000003\n",
      "Epoch [6200/10000], Loss: 0.000003\n",
      "Epoch [6300/10000], Loss: 0.000003\n",
      "Epoch [6400/10000], Loss: 0.000003\n",
      "Epoch [6500/10000], Loss: 0.000003\n",
      "Epoch [6600/10000], Loss: 0.000002\n",
      "Epoch [6700/10000], Loss: 0.000022\n",
      "Epoch [6800/10000], Loss: 0.000002\n",
      "Epoch [6900/10000], Loss: 0.000002\n",
      "Epoch [7000/10000], Loss: 0.000002\n",
      "Epoch [7100/10000], Loss: 0.000002\n",
      "Epoch [7200/10000], Loss: 0.000017\n",
      "Epoch [7300/10000], Loss: 0.000002\n",
      "Epoch [7400/10000], Loss: 0.000002\n",
      "Epoch [7500/10000], Loss: 0.000002\n",
      "Epoch [7600/10000], Loss: 0.000002\n",
      "Epoch [7700/10000], Loss: 0.000003\n",
      "Epoch [7800/10000], Loss: 0.000002\n",
      "Epoch [7900/10000], Loss: 0.000002\n",
      "Epoch [8000/10000], Loss: 0.000022\n",
      "Epoch [8100/10000], Loss: 0.000002\n",
      "Epoch [8200/10000], Loss: 0.000002\n",
      "Epoch [8300/10000], Loss: 0.000002\n",
      "Epoch [8400/10000], Loss: 0.000002\n",
      "Epoch [8500/10000], Loss: 0.000002\n",
      "Epoch [8600/10000], Loss: 0.000002\n",
      "Epoch [8700/10000], Loss: 0.000002\n",
      "Epoch [8800/10000], Loss: 0.000002\n",
      "Epoch [8900/10000], Loss: 0.000002\n",
      "Epoch [9000/10000], Loss: 0.000002\n",
      "Epoch [9100/10000], Loss: 0.000005\n",
      "Epoch [9200/10000], Loss: 0.000002\n",
      "Epoch [9300/10000], Loss: 0.000002\n",
      "Epoch [9400/10000], Loss: 0.000003\n",
      "Epoch [9500/10000], Loss: 0.000002\n",
      "Epoch [9600/10000], Loss: 0.000002\n",
      "Epoch [9700/10000], Loss: 0.000002\n",
      "Epoch [9800/10000], Loss: 0.000002\n",
      "Epoch [9900/10000], Loss: 0.000002\n",
      "Epoch [10000/10000], Loss: 0.000002\n"
     ]
    }
   ],
   "source": [
    "train_model(model_cos, criterion, optimizer_cos, x_train_cos, y_train_cos, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d910223-f12d-44a3-9b43-4b1391df5dce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.114912\n",
      "Epoch [200/10000], Loss: 0.051883\n",
      "Epoch [300/10000], Loss: 0.013478\n",
      "Epoch [400/10000], Loss: 0.005415\n",
      "Epoch [500/10000], Loss: 0.004374\n",
      "Epoch [600/10000], Loss: 0.003781\n",
      "Epoch [700/10000], Loss: 0.003277\n",
      "Epoch [800/10000], Loss: 0.002842\n",
      "Epoch [900/10000], Loss: 0.002460\n",
      "Epoch [1000/10000], Loss: 0.002120\n",
      "Epoch [1100/10000], Loss: 0.001817\n",
      "Epoch [1200/10000], Loss: 0.001545\n",
      "Epoch [1300/10000], Loss: 0.001302\n",
      "Epoch [1400/10000], Loss: 0.001085\n",
      "Epoch [1500/10000], Loss: 0.000893\n",
      "Epoch [1600/10000], Loss: 0.000726\n",
      "Epoch [1700/10000], Loss: 0.000583\n",
      "Epoch [1800/10000], Loss: 0.000462\n",
      "Epoch [1900/10000], Loss: 0.000362\n",
      "Epoch [2000/10000], Loss: 0.000281\n",
      "Epoch [2100/10000], Loss: 0.000217\n",
      "Epoch [2200/10000], Loss: 0.000168\n",
      "Epoch [2300/10000], Loss: 0.000131\n",
      "Epoch [2400/10000], Loss: 0.000104\n",
      "Epoch [2500/10000], Loss: 0.000085\n",
      "Epoch [2600/10000], Loss: 0.000071\n",
      "Epoch [2700/10000], Loss: 0.000061\n",
      "Epoch [2800/10000], Loss: 0.000053\n",
      "Epoch [2900/10000], Loss: 0.000048\n",
      "Epoch [3000/10000], Loss: 0.000043\n",
      "Epoch [3100/10000], Loss: 0.000040\n",
      "Epoch [3200/10000], Loss: 0.000036\n",
      "Epoch [3300/10000], Loss: 0.000034\n",
      "Epoch [3400/10000], Loss: 0.000031\n",
      "Epoch [3500/10000], Loss: 0.000029\n",
      "Epoch [3600/10000], Loss: 0.000027\n",
      "Epoch [3700/10000], Loss: 0.000025\n",
      "Epoch [3800/10000], Loss: 0.000023\n",
      "Epoch [3900/10000], Loss: 0.000022\n",
      "Epoch [4000/10000], Loss: 0.000020\n",
      "Epoch [4100/10000], Loss: 0.000019\n",
      "Epoch [4200/10000], Loss: 0.000017\n",
      "Epoch [4300/10000], Loss: 0.000016\n",
      "Epoch [4400/10000], Loss: 0.000015\n",
      "Epoch [4500/10000], Loss: 0.000014\n",
      "Epoch [4600/10000], Loss: 0.000013\n",
      "Epoch [4700/10000], Loss: 0.000012\n",
      "Epoch [4800/10000], Loss: 0.000011\n",
      "Epoch [4900/10000], Loss: 0.000010\n",
      "Epoch [5000/10000], Loss: 0.000010\n",
      "Epoch [5100/10000], Loss: 0.000009\n",
      "Epoch [5200/10000], Loss: 0.000008\n",
      "Epoch [5300/10000], Loss: 0.000008\n",
      "Epoch [5400/10000], Loss: 0.000007\n",
      "Epoch [5500/10000], Loss: 0.000006\n",
      "Epoch [5600/10000], Loss: 0.000006\n",
      "Epoch [5700/10000], Loss: 0.000005\n",
      "Epoch [5800/10000], Loss: 0.000005\n",
      "Epoch [5900/10000], Loss: 0.000004\n",
      "Epoch [6000/10000], Loss: 0.000004\n",
      "Epoch [6100/10000], Loss: 0.000004\n",
      "Epoch [6200/10000], Loss: 0.000003\n",
      "Epoch [6300/10000], Loss: 0.000003\n",
      "Epoch [6400/10000], Loss: 0.000003\n",
      "Epoch [6500/10000], Loss: 0.000003\n",
      "Epoch [6600/10000], Loss: 0.000002\n",
      "Epoch [6700/10000], Loss: 0.000002\n",
      "Epoch [6800/10000], Loss: 0.000002\n",
      "Epoch [6900/10000], Loss: 0.000002\n",
      "Epoch [7000/10000], Loss: 0.000002\n",
      "Epoch [7100/10000], Loss: 0.000002\n",
      "Epoch [7200/10000], Loss: 0.000001\n",
      "Epoch [7300/10000], Loss: 0.000001\n",
      "Epoch [7400/10000], Loss: 0.000001\n",
      "Epoch [7500/10000], Loss: 0.000001\n",
      "Epoch [7600/10000], Loss: 0.000001\n",
      "Epoch [7700/10000], Loss: 0.000001\n",
      "Epoch [7800/10000], Loss: 0.000001\n",
      "Epoch [7900/10000], Loss: 0.000001\n",
      "Epoch [8000/10000], Loss: 0.000001\n",
      "Epoch [8100/10000], Loss: 0.000001\n",
      "Epoch [8200/10000], Loss: 0.000001\n",
      "Epoch [8300/10000], Loss: 0.000003\n",
      "Epoch [8400/10000], Loss: 0.000001\n",
      "Epoch [8500/10000], Loss: 0.000008\n",
      "Epoch [8600/10000], Loss: 0.000001\n",
      "Epoch [8700/10000], Loss: 0.000001\n",
      "Epoch [8800/10000], Loss: 0.000001\n",
      "Epoch [8900/10000], Loss: 0.000001\n",
      "Epoch [9000/10000], Loss: 0.000001\n",
      "Epoch [9100/10000], Loss: 0.000001\n",
      "Epoch [9200/10000], Loss: 0.000001\n",
      "Epoch [9300/10000], Loss: 0.000015\n",
      "Epoch [9400/10000], Loss: 0.000001\n",
      "Epoch [9500/10000], Loss: 0.000001\n",
      "Epoch [9600/10000], Loss: 0.000006\n",
      "Epoch [9700/10000], Loss: 0.000001\n",
      "Epoch [9800/10000], Loss: 0.000001\n",
      "Epoch [9900/10000], Loss: 0.000004\n",
      "Epoch [10000/10000], Loss: 0.000001\n"
     ]
    }
   ],
   "source": [
    "train_model(model_exp, criterion, optimizer_exp, x_train_exp, y_train_exp, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9f25a-6b78-42d6-b07a-317296a54880",
   "metadata": {},
   "source": [
    "### Extractoin of the parameters of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19dce1d3-1b8d-4716-9d14-408de4431a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_params(model):\n",
    "    b1 = model.input_layer.bias.detach().numpy()\n",
    "    weights_w1 = model.input_layer.weight.detach().numpy().flatten()\n",
    "    b2 = model.output_layer.bias.item()\n",
    "    weights_w2 = model.output_layer.weight.detach().numpy().flatten()\n",
    "\n",
    "    return b1, weights_w1, b2, weights_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0576319-05e1-4828-8c2d-e2a57c092162",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_cos, weights_w1_cos, b2_cos, weights_w2_cos = extract_model_params(model_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26596c2e-271f-49ad-ac8a-95942825645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_exp, weights_w1_exp, b2_exp, weights_w2_exp = extract_model_params(model_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3845e2-89b7-4bfa-8d83-789d9f1d57c3",
   "metadata": {},
   "source": [
    "### Integreation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b4b85c-e2f8-400a-be87-f5c63cd7c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "beta = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4afb7e-ba84-4db5-a60b-9f0143c23e6b",
   "metadata": {},
   "source": [
    "### NNI integral calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2a7974-e3f0-4fbb-9c93-5f33614f6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_cos = get_NN_analytical_integral(alpha, beta, b1_cos, b2_cos, weights_w1_cos, weights_w2_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46088489-19e4-4de6-b09e-2676dbb4cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of cos(x) of the trained neural network model is: 0.841397\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of cos(x) of the trained neural network model is: {float(integral_cos):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d13e1e4-36d7-434b-a986-8f0a95f03e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_exp = get_NN_analytical_integral(alpha, beta, b1_exp, b2_exp, weights_w1_exp, weights_w2_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bc036b6-b92e-42d7-acf2-a70ea1c3f71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of exp(x) of the trained neural network model is: 1.718245\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of exp(x) of the trained neural network model is: {float(integral_exp):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48461cd1-49f7-48c7-ac33-9ae65a4143fe",
   "metadata": {},
   "source": [
    "### True integral for comparison\n",
    "\n",
    "$\\int_{\\alpha}^{\\beta} dx\\{cos(x)\\} = sin(\\beta) - sin(\\alpha) $\n",
    "\n",
    "$\\int_{\\alpha}^{\\beta} dx\\{exp(x)\\} = exp(\\beta) - exp(\\alpha) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95abe020-53e7-4ba1-b382-30de9a5398bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_integral_cos = np.sin(beta) - np.sin(alpha)\n",
    "true_integral_exp = np.exp(beta) - np.exp(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "250a1cda-25c1-47d3-9832-f2371acc7932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true cosinus integral is: 0.841471\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true cosinus integral is: {float(true_integral_cos):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14ff1e16-cd4b-48fa-aae4-4a045aa16f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true exponent integral is: 1.718282\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true exponent integral is: {float(true_integral_exp):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e5bfc-1672-4b23-a1f2-cbc47a4276af",
   "metadata": {},
   "source": [
    "## Integration of function 1.1.1:\n",
    "\n",
    "$ \\int_{0}^{1}d\\alpha\\{ \\alpha^a(1 - \\alpha)^b \\}, a = 1, b = 1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22b07380-7149-4749-a8b5-c2a545a3a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 1\n",
    "\n",
    "def alpha_func(alpha):\n",
    "    return alpha ** a * (1 - alpha) ** b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cce6e8d0-7b3c-4adb-8a83-00ea46ad0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alpha = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_alpha = optim.Adam(model_alpha.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15833013-2565-4e6f-9244-9c201607b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_alpha, y_train_alpha = generate_data(alpha_func, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6009851-176e-4a46-a7cf-bf44730155d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.005684\n",
      "Epoch [200/10000], Loss: 0.005455\n",
      "Epoch [300/10000], Loss: 0.005377\n",
      "Epoch [400/10000], Loss: 0.005307\n",
      "Epoch [500/10000], Loss: 0.005215\n",
      "Epoch [600/10000], Loss: 0.005091\n",
      "Epoch [700/10000], Loss: 0.004923\n",
      "Epoch [800/10000], Loss: 0.004690\n",
      "Epoch [900/10000], Loss: 0.004360\n",
      "Epoch [1000/10000], Loss: 0.003886\n",
      "Epoch [1100/10000], Loss: 0.003213\n",
      "Epoch [1200/10000], Loss: 0.002341\n",
      "Epoch [1300/10000], Loss: 0.001413\n",
      "Epoch [1400/10000], Loss: 0.000701\n",
      "Epoch [1500/10000], Loss: 0.000354\n",
      "Epoch [1600/10000], Loss: 0.000240\n",
      "Epoch [1700/10000], Loss: 0.000195\n",
      "Epoch [1800/10000], Loss: 0.000164\n",
      "Epoch [1900/10000], Loss: 0.000137\n",
      "Epoch [2000/10000], Loss: 0.000115\n",
      "Epoch [2100/10000], Loss: 0.000097\n",
      "Epoch [2200/10000], Loss: 0.000083\n",
      "Epoch [2300/10000], Loss: 0.000072\n",
      "Epoch [2400/10000], Loss: 0.000064\n",
      "Epoch [2500/10000], Loss: 0.000058\n",
      "Epoch [2600/10000], Loss: 0.000053\n",
      "Epoch [2700/10000], Loss: 0.000050\n",
      "Epoch [2800/10000], Loss: 0.000048\n",
      "Epoch [2900/10000], Loss: 0.000046\n",
      "Epoch [3000/10000], Loss: 0.000044\n",
      "Epoch [3100/10000], Loss: 0.000043\n",
      "Epoch [3200/10000], Loss: 0.000041\n",
      "Epoch [3300/10000], Loss: 0.000040\n",
      "Epoch [3400/10000], Loss: 0.000039\n",
      "Epoch [3500/10000], Loss: 0.000037\n",
      "Epoch [3600/10000], Loss: 0.000036\n",
      "Epoch [3700/10000], Loss: 0.000035\n",
      "Epoch [3800/10000], Loss: 0.000034\n",
      "Epoch [3900/10000], Loss: 0.000032\n",
      "Epoch [4000/10000], Loss: 0.000031\n",
      "Epoch [4100/10000], Loss: 0.000030\n",
      "Epoch [4200/10000], Loss: 0.000028\n",
      "Epoch [4300/10000], Loss: 0.000027\n",
      "Epoch [4400/10000], Loss: 0.000026\n",
      "Epoch [4500/10000], Loss: 0.000024\n",
      "Epoch [4600/10000], Loss: 0.000023\n",
      "Epoch [4700/10000], Loss: 0.000022\n",
      "Epoch [4800/10000], Loss: 0.000020\n",
      "Epoch [4900/10000], Loss: 0.000019\n",
      "Epoch [5000/10000], Loss: 0.000018\n",
      "Epoch [5100/10000], Loss: 0.000016\n",
      "Epoch [5200/10000], Loss: 0.000015\n",
      "Epoch [5300/10000], Loss: 0.000021\n",
      "Epoch [5400/10000], Loss: 0.000013\n",
      "Epoch [5500/10000], Loss: 0.000013\n",
      "Epoch [5600/10000], Loss: 0.000012\n",
      "Epoch [5700/10000], Loss: 0.000011\n",
      "Epoch [5800/10000], Loss: 0.000010\n",
      "Epoch [5900/10000], Loss: 0.000010\n",
      "Epoch [6000/10000], Loss: 0.000009\n",
      "Epoch [6100/10000], Loss: 0.000121\n",
      "Epoch [6200/10000], Loss: 0.000008\n",
      "Epoch [6300/10000], Loss: 0.000008\n",
      "Epoch [6400/10000], Loss: 0.000023\n",
      "Epoch [6500/10000], Loss: 0.000007\n",
      "Epoch [6600/10000], Loss: 0.000006\n",
      "Epoch [6700/10000], Loss: 0.000006\n",
      "Epoch [6800/10000], Loss: 0.000005\n",
      "Epoch [6900/10000], Loss: 0.000005\n",
      "Epoch [7000/10000], Loss: 0.000005\n",
      "Epoch [7100/10000], Loss: 0.000004\n",
      "Epoch [7200/10000], Loss: 0.000004\n",
      "Epoch [7300/10000], Loss: 0.000004\n",
      "Epoch [7400/10000], Loss: 0.000004\n",
      "Epoch [7500/10000], Loss: 0.000081\n",
      "Epoch [7600/10000], Loss: 0.000003\n",
      "Epoch [7700/10000], Loss: 0.000003\n",
      "Epoch [7800/10000], Loss: 0.000008\n",
      "Epoch [7900/10000], Loss: 0.000003\n",
      "Epoch [8000/10000], Loss: 0.000002\n",
      "Epoch [8100/10000], Loss: 0.000003\n",
      "Epoch [8200/10000], Loss: 0.000002\n",
      "Epoch [8300/10000], Loss: 0.000002\n",
      "Epoch [8400/10000], Loss: 0.000002\n",
      "Epoch [8500/10000], Loss: 0.000002\n",
      "Epoch [8600/10000], Loss: 0.000002\n",
      "Epoch [8700/10000], Loss: 0.000002\n",
      "Epoch [8800/10000], Loss: 0.000001\n",
      "Epoch [8900/10000], Loss: 0.000001\n",
      "Epoch [9000/10000], Loss: 0.000001\n",
      "Epoch [9100/10000], Loss: 0.000001\n",
      "Epoch [9200/10000], Loss: 0.000001\n",
      "Epoch [9300/10000], Loss: 0.000001\n",
      "Epoch [9400/10000], Loss: 0.000001\n",
      "Epoch [9500/10000], Loss: 0.000001\n",
      "Epoch [9600/10000], Loss: 0.000001\n",
      "Epoch [9700/10000], Loss: 0.000001\n",
      "Epoch [9800/10000], Loss: 0.000001\n",
      "Epoch [9900/10000], Loss: 0.000001\n",
      "Epoch [10000/10000], Loss: 0.000001\n"
     ]
    }
   ],
   "source": [
    "train_model(model_alpha, criterion, optimizer_alpha, x_train_alpha, y_train_alpha, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59e4d09b-8241-4904-9354-12c2b7f7d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_alpha, weights_w1_alpha, b2_alpha, weights_w2_alpha = extract_model_params(model_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a22f3a12-6d5e-4e24-9739-bfe2b240a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_alpha = get_NN_analytical_integral(alpha, beta, b1_alpha, b2_alpha, weights_w1_alpha, weights_w2_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f10235fe-234e-4ffd-9ad4-ab90b3ab1539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of exp(x) of the trained neural network model is: 0.166666\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of exp(x) of the trained neural network model is: {float(integral_alpha):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ee0cb3-3321-43c2-b5d0-2a7efdf37f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_integral_alpha = (1/2 - 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29cf3a2d-912d-4df0-9d77-8f69da76cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true cosinus integral is: 0.166667\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true cosinus integral is: {float(true_integral_alpha):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a33bcb-40a0-40c1-b4b3-b6e6629c79f6",
   "metadata": {},
   "source": [
    "## Integration of function 1.1.2:\n",
    "\n",
    "$ \\int_{0}^{1}d\\alpha\\{ \\alpha^a(1 - \\alpha)^b \\}, a = 0, b = 1 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7aa7439-377d-4b5d-b7d2-53d1303ed0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4fdaea7-4fd1-4b75-802a-6ca040985214",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_alpha_2 = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_alpha = optim.Adam(model_alpha_2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0b9aec8-d438-4406-9deb-b70d463aaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_alpha_2, y_train_alpha_2 = generate_data(alpha_func, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7c58dbc-85c4-4fed-8fff-794d29b7ed16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.000119\n",
      "Epoch [200/10000], Loss: 0.000020\n",
      "Epoch [300/10000], Loss: 0.000015\n",
      "Epoch [400/10000], Loss: 0.000011\n",
      "Epoch [500/10000], Loss: 0.000008\n",
      "Epoch [600/10000], Loss: 0.000006\n",
      "Epoch [700/10000], Loss: 0.000005\n",
      "Epoch [800/10000], Loss: 0.000004\n",
      "Epoch [900/10000], Loss: 0.000004\n",
      "Epoch [1000/10000], Loss: 0.000003\n",
      "Epoch [1100/10000], Loss: 0.000003\n",
      "Epoch [1200/10000], Loss: 0.000003\n",
      "Epoch [1300/10000], Loss: 0.000003\n",
      "Epoch [1400/10000], Loss: 0.000003\n",
      "Epoch [1500/10000], Loss: 0.000003\n",
      "Epoch [1600/10000], Loss: 0.000003\n",
      "Epoch [1700/10000], Loss: 0.000003\n",
      "Epoch [1800/10000], Loss: 0.000003\n",
      "Epoch [1900/10000], Loss: 0.000003\n",
      "Epoch [2000/10000], Loss: 0.000004\n",
      "Epoch [2100/10000], Loss: 0.000003\n",
      "Epoch [2200/10000], Loss: 0.000006\n",
      "Epoch [2300/10000], Loss: 0.000003\n",
      "Epoch [2400/10000], Loss: 0.000003\n",
      "Epoch [2500/10000], Loss: 0.000003\n",
      "Epoch [2600/10000], Loss: 0.000003\n",
      "Epoch [2700/10000], Loss: 0.000003\n",
      "Epoch [2800/10000], Loss: 0.000045\n",
      "Epoch [2900/10000], Loss: 0.000003\n",
      "Epoch [3000/10000], Loss: 0.000003\n",
      "Epoch [3100/10000], Loss: 0.000003\n",
      "Epoch [3200/10000], Loss: 0.000003\n",
      "Epoch [3300/10000], Loss: 0.000003\n",
      "Epoch [3400/10000], Loss: 0.000006\n",
      "Epoch [3500/10000], Loss: 0.000003\n",
      "Epoch [3600/10000], Loss: 0.000003\n",
      "Epoch [3700/10000], Loss: 0.000003\n",
      "Epoch [3800/10000], Loss: 0.000002\n",
      "Epoch [3900/10000], Loss: 0.000150\n",
      "Epoch [4000/10000], Loss: 0.000002\n",
      "Epoch [4100/10000], Loss: 0.000002\n",
      "Epoch [4200/10000], Loss: 0.000014\n",
      "Epoch [4300/10000], Loss: 0.000002\n",
      "Epoch [4400/10000], Loss: 0.000002\n",
      "Epoch [4500/10000], Loss: 0.000008\n",
      "Epoch [4600/10000], Loss: 0.000002\n",
      "Epoch [4700/10000], Loss: 0.000002\n",
      "Epoch [4800/10000], Loss: 0.000002\n",
      "Epoch [4900/10000], Loss: 0.000002\n",
      "Epoch [5000/10000], Loss: 0.000002\n",
      "Epoch [5100/10000], Loss: 0.000002\n",
      "Epoch [5200/10000], Loss: 0.000002\n",
      "Epoch [5300/10000], Loss: 0.000002\n",
      "Epoch [5400/10000], Loss: 0.000003\n",
      "Epoch [5500/10000], Loss: 0.000002\n",
      "Epoch [5600/10000], Loss: 0.000002\n",
      "Epoch [5700/10000], Loss: 0.000003\n",
      "Epoch [5800/10000], Loss: 0.000002\n",
      "Epoch [5900/10000], Loss: 0.000002\n",
      "Epoch [6000/10000], Loss: 0.000002\n",
      "Epoch [6100/10000], Loss: 0.000002\n",
      "Epoch [6200/10000], Loss: 0.000051\n",
      "Epoch [6300/10000], Loss: 0.000002\n",
      "Epoch [6400/10000], Loss: 0.000002\n",
      "Epoch [6500/10000], Loss: 0.000006\n",
      "Epoch [6600/10000], Loss: 0.000002\n",
      "Epoch [6700/10000], Loss: 0.000002\n",
      "Epoch [6800/10000], Loss: 0.000002\n",
      "Epoch [6900/10000], Loss: 0.000002\n",
      "Epoch [7000/10000], Loss: 0.000002\n",
      "Epoch [7100/10000], Loss: 0.000002\n",
      "Epoch [7200/10000], Loss: 0.000002\n",
      "Epoch [7300/10000], Loss: 0.000002\n",
      "Epoch [7400/10000], Loss: 0.000002\n",
      "Epoch [7500/10000], Loss: 0.000002\n",
      "Epoch [7600/10000], Loss: 0.000008\n",
      "Epoch [7700/10000], Loss: 0.000002\n",
      "Epoch [7800/10000], Loss: 0.000002\n",
      "Epoch [7900/10000], Loss: 0.000016\n",
      "Epoch [8000/10000], Loss: 0.000002\n",
      "Epoch [8100/10000], Loss: 0.000002\n",
      "Epoch [8200/10000], Loss: 0.000016\n",
      "Epoch [8300/10000], Loss: 0.000002\n",
      "Epoch [8400/10000], Loss: 0.000002\n",
      "Epoch [8500/10000], Loss: 0.000003\n",
      "Epoch [8600/10000], Loss: 0.000002\n",
      "Epoch [8700/10000], Loss: 0.000002\n",
      "Epoch [8800/10000], Loss: 0.000004\n",
      "Epoch [8900/10000], Loss: 0.000002\n",
      "Epoch [9000/10000], Loss: 0.000002\n",
      "Epoch [9100/10000], Loss: 0.000002\n",
      "Epoch [9200/10000], Loss: 0.000002\n",
      "Epoch [9300/10000], Loss: 0.000002\n",
      "Epoch [9400/10000], Loss: 0.000002\n",
      "Epoch [9500/10000], Loss: 0.000002\n",
      "Epoch [9600/10000], Loss: 0.000002\n",
      "Epoch [9700/10000], Loss: 0.000001\n",
      "Epoch [9800/10000], Loss: 0.000001\n",
      "Epoch [9900/10000], Loss: 0.000001\n",
      "Epoch [10000/10000], Loss: 0.000001\n"
     ]
    }
   ],
   "source": [
    "train_model(model_alpha_2, criterion, optimizer_alpha, x_train_alpha_2, y_train_alpha_2, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4310ca0b-4fb2-48dc-bda7-36858d7c8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_alpha_2, weights_w1_alpha_2, b2_alpha_2, weights_w2_alpha_2 = extract_model_params(model_alpha_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538defd6-2c7d-4dbc-9827-e7131bbe819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_alpha_2 = get_NN_analytical_integral(alpha, beta, b1_alpha_2, b2_alpha_2, weights_w1_alpha_2, weights_w2_alpha_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8719326f-d598-4f79-bb24-748183107d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of alpha^a(1 - alpha)^b of the trained neural network model is: 0.500068\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of alpha^a(1 - alpha)^b of the trained neural network model is: {float(integral_alpha_2):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df5e8b2b-b9c3-4a64-a5ce-7c3ed5b45535",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_integral_alpha_2 = (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44aa66b2-dd70-4eca-9073-a2a50a9848c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true cosinus integral is: 0.500000\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true cosinus integral is: {float(true_integral_alpha_2):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae31417d-3c4a-42a7-b08e-026a89e7c3f1",
   "metadata": {},
   "source": [
    "## Integration of function 1.1.3:\n",
    "\n",
    "$ \\int_{0}^{1}d\\alpha\\{ \\alpha^a(1 - \\alpha)^b \\}, a = 1, b = 0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9649827-b91b-4106-9e0e-108ca4990801",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18355537-fcd0-417e-86ed-1531f80a7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alpha_3 = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_alpha = optim.Adam(model_alpha_3.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df13ebc4-a86d-4807-8ed0-a3199cae8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_alpha_3, y_train_alpha_3 = generate_data(alpha_func, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f03a18e5-1af0-4b9a-8713-953d9812ffdc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.011990\n",
      "Epoch [200/10000], Loss: 0.000017\n",
      "Epoch [300/10000], Loss: 0.000015\n",
      "Epoch [400/10000], Loss: 0.000014\n",
      "Epoch [500/10000], Loss: 0.000013\n",
      "Epoch [600/10000], Loss: 0.000013\n",
      "Epoch [700/10000], Loss: 0.000012\n",
      "Epoch [800/10000], Loss: 0.000012\n",
      "Epoch [900/10000], Loss: 0.000011\n",
      "Epoch [1000/10000], Loss: 0.000011\n",
      "Epoch [1100/10000], Loss: 0.000011\n",
      "Epoch [1200/10000], Loss: 0.000011\n",
      "Epoch [1300/10000], Loss: 0.000010\n",
      "Epoch [1400/10000], Loss: 0.000010\n",
      "Epoch [1500/10000], Loss: 0.000010\n",
      "Epoch [1600/10000], Loss: 0.000010\n",
      "Epoch [1700/10000], Loss: 0.000010\n",
      "Epoch [1800/10000], Loss: 0.000010\n",
      "Epoch [1900/10000], Loss: 0.000010\n",
      "Epoch [2000/10000], Loss: 0.000010\n",
      "Epoch [2100/10000], Loss: 0.000009\n",
      "Epoch [2200/10000], Loss: 0.000009\n",
      "Epoch [2300/10000], Loss: 0.000009\n",
      "Epoch [2400/10000], Loss: 0.000009\n",
      "Epoch [2500/10000], Loss: 0.000009\n",
      "Epoch [2600/10000], Loss: 0.000009\n",
      "Epoch [2700/10000], Loss: 0.000009\n",
      "Epoch [2800/10000], Loss: 0.000008\n",
      "Epoch [2900/10000], Loss: 0.000008\n",
      "Epoch [3000/10000], Loss: 0.000008\n",
      "Epoch [3100/10000], Loss: 0.000008\n",
      "Epoch [3200/10000], Loss: 0.000008\n",
      "Epoch [3300/10000], Loss: 0.000008\n",
      "Epoch [3400/10000], Loss: 0.000007\n",
      "Epoch [3500/10000], Loss: 0.000007\n",
      "Epoch [3600/10000], Loss: 0.000007\n",
      "Epoch [3700/10000], Loss: 0.000007\n",
      "Epoch [3800/10000], Loss: 0.000007\n",
      "Epoch [3900/10000], Loss: 0.000007\n",
      "Epoch [4000/10000], Loss: 0.000006\n",
      "Epoch [4100/10000], Loss: 0.000006\n",
      "Epoch [4200/10000], Loss: 0.000006\n",
      "Epoch [4300/10000], Loss: 0.000006\n",
      "Epoch [4400/10000], Loss: 0.000006\n",
      "Epoch [4500/10000], Loss: 0.000006\n",
      "Epoch [4600/10000], Loss: 0.000006\n",
      "Epoch [4700/10000], Loss: 0.000005\n",
      "Epoch [4800/10000], Loss: 0.000005\n",
      "Epoch [4900/10000], Loss: 0.000005\n",
      "Epoch [5000/10000], Loss: 0.000005\n",
      "Epoch [5100/10000], Loss: 0.000005\n",
      "Epoch [5200/10000], Loss: 0.000005\n",
      "Epoch [5300/10000], Loss: 0.000005\n",
      "Epoch [5400/10000], Loss: 0.000005\n",
      "Epoch [5500/10000], Loss: 0.000005\n",
      "Epoch [5600/10000], Loss: 0.000004\n",
      "Epoch [5700/10000], Loss: 0.000092\n",
      "Epoch [5800/10000], Loss: 0.000004\n",
      "Epoch [5900/10000], Loss: 0.000004\n",
      "Epoch [6000/10000], Loss: 0.000004\n",
      "Epoch [6100/10000], Loss: 0.000005\n",
      "Epoch [6200/10000], Loss: 0.000004\n",
      "Epoch [6300/10000], Loss: 0.000004\n",
      "Epoch [6400/10000], Loss: 0.000004\n",
      "Epoch [6500/10000], Loss: 0.000004\n",
      "Epoch [6600/10000], Loss: 0.000004\n",
      "Epoch [6700/10000], Loss: 0.000004\n",
      "Epoch [6800/10000], Loss: 0.000004\n",
      "Epoch [6900/10000], Loss: 0.000038\n",
      "Epoch [7000/10000], Loss: 0.000004\n",
      "Epoch [7100/10000], Loss: 0.000004\n",
      "Epoch [7200/10000], Loss: 0.000007\n",
      "Epoch [7300/10000], Loss: 0.000003\n",
      "Epoch [7400/10000], Loss: 0.000003\n",
      "Epoch [7500/10000], Loss: 0.000003\n",
      "Epoch [7600/10000], Loss: 0.000003\n",
      "Epoch [7700/10000], Loss: 0.000003\n",
      "Epoch [7800/10000], Loss: 0.000012\n",
      "Epoch [7900/10000], Loss: 0.000003\n",
      "Epoch [8000/10000], Loss: 0.000003\n",
      "Epoch [8100/10000], Loss: 0.000003\n",
      "Epoch [8200/10000], Loss: 0.000003\n",
      "Epoch [8300/10000], Loss: 0.000003\n",
      "Epoch [8400/10000], Loss: 0.000003\n",
      "Epoch [8500/10000], Loss: 0.000003\n",
      "Epoch [8600/10000], Loss: 0.000003\n",
      "Epoch [8700/10000], Loss: 0.000003\n",
      "Epoch [8800/10000], Loss: 0.000003\n",
      "Epoch [8900/10000], Loss: 0.000022\n",
      "Epoch [9000/10000], Loss: 0.000003\n",
      "Epoch [9100/10000], Loss: 0.000003\n",
      "Epoch [9200/10000], Loss: 0.000003\n",
      "Epoch [9300/10000], Loss: 0.000003\n",
      "Epoch [9400/10000], Loss: 0.000003\n",
      "Epoch [9500/10000], Loss: 0.000003\n",
      "Epoch [9600/10000], Loss: 0.000003\n",
      "Epoch [9700/10000], Loss: 0.000003\n",
      "Epoch [9800/10000], Loss: 0.000003\n",
      "Epoch [9900/10000], Loss: 0.000003\n",
      "Epoch [10000/10000], Loss: 0.000150\n"
     ]
    }
   ],
   "source": [
    "train_model(model_alpha_3, criterion, optimizer_alpha, x_train_alpha_3, y_train_alpha_3, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ced919e-cfdc-4498-9333-9a4f37c596c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_alpha_3, weights_w1_alpha_3, b2_alpha_3, weights_w2_alpha_3 = extract_model_params(model_alpha_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21dbc83a-17f3-4e1a-9632-02de2876ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_alpha_3 = get_NN_analytical_integral(alpha, beta, b1_alpha_3, b2_alpha_3, weights_w1_alpha_3, weights_w2_alpha_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "daa13908-aacd-4283-8d47-a6be6828b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of alpha^a(1 - alpha)^b of the trained neural network model is: 0.488403\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of alpha^a(1 - alpha)^b of the trained neural network model is: {float(integral_alpha_3):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fb54fde-4084-4093-81ab-7394e40043bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_integral_alpha_3 = (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0cb80f36-f74f-4fee-b7d9-2154203e149c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true cosinus integral is: 0.500000\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true cosinus integral is: {float(true_integral_alpha_3):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28ed6a-206b-4582-8839-ef1f33f60b02",
   "metadata": {},
   "source": [
    "## Integration of function 1.2:\n",
    "\n",
    "$ \\frac{t^m}{(1+t)^n}F[z_{0}], m = 2, n = 2 $\n",
    "\n",
    "$ F[z_0] = exp[-2z_0] $\n",
    "\n",
    "$ z_0 = tD + \\frac{t}{1 + t}R^2 $\n",
    "\n",
    "$ D = \\alpha_1(b_1^{2}P^2 + m_1^2) + \\alpha_2(b_2^{2}P^2 + m_2^2) $\n",
    "\n",
    "$ R^2 = \\alpha_1^{2}b_1^2 + \\alpha_2^{2}b_2^2 + 2\\alpha_{1}\\alpha_{2}(m_{1}m_2) $\n",
    "\n",
    "$ b_1 = -\\frac{m_1}{m_1 + m_2} $ \n",
    " \n",
    "$ b_2 = \\frac{m_1}{m_1 + m_2} $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5999d98-6c9b-4813-a17c-84f13e97784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "n = 2\n",
    "\n",
    "alpha1 = 2.4\n",
    "alpha2 = alpha1\n",
    "\n",
    "m1 = 0.7083333\n",
    "m2 = 0.7083333\n",
    "PP = -1.665046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a6167ba-7e3a-4db1-94f7-9ad61aa2055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_func(t):\n",
    "    return t**m / (1 + t)**n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db5b95c0-2e4a-43cf-b40a-988c0fc0a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b1_func():\n",
    "    return - m1 / (m1 + m2)\n",
    "\n",
    "def b2_func():\n",
    "    return m1 / (m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d520fd02-4d41-41c7-a955-c3456c0446a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_func():\n",
    "    b1b1 = b1_func() ** 2\n",
    "    b2b2 = b2_func() ** 2\n",
    "    \n",
    "    return alpha1 * (b1b1 * PP + m1**2) + alpha2 * (b2b2 * PP + m2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4798231a-360a-489a-acc6-15e8ae56b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RR_func():\n",
    "    b1b1 = b1_func() ** 2\n",
    "    b2b2 = b2_func() ** 2\n",
    "    \n",
    "    return alpha1**2 * b1b1 + alpha2**2 * b2b2 + 2 * alpha1 * alpha2 * (m1 * m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ad163d8-045a-4494-b811-b223161c71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z0_func(t):\n",
    "    D = D_func()\n",
    "    RR = RR_func()\n",
    "    return t * D + t / (1 + t) * RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35f28001-3062-49ed-8789-3d9e1e08efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_func(t):\n",
    "    z_0 = z0_func(t)\n",
    "    return np.exp(-2*z_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb52b271-8ee2-4126-812d-ab4313fed744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tF_func(t):\n",
    "    return t_func(t) * F_func(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15cbd347-7e15-46db-8cea-28681adc8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tF = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_tF = optim.Adam(model_tF.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fcdc138-6cd0-4a85-b073-a80983a577a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tF, y_train_tF = generate_data(tF_func, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe2ead40-1f9a-4b8d-a509-1385a9ae062b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.000053\n",
      "Epoch [200/10000], Loss: 0.000000\n",
      "Epoch [300/10000], Loss: 0.000000\n",
      "Epoch [400/10000], Loss: 0.000000\n",
      "Epoch [500/10000], Loss: 0.000000\n",
      "Epoch [600/10000], Loss: 0.000000\n",
      "Epoch [700/10000], Loss: 0.000000\n",
      "Epoch [800/10000], Loss: 0.000000\n",
      "Epoch [900/10000], Loss: 0.000000\n",
      "Epoch [1000/10000], Loss: 0.000000\n",
      "Epoch [1100/10000], Loss: 0.000000\n",
      "Epoch [1200/10000], Loss: 0.000000\n",
      "Epoch [1300/10000], Loss: 0.000000\n",
      "Epoch [1400/10000], Loss: 0.000000\n",
      "Epoch [1500/10000], Loss: 0.000000\n",
      "Epoch [1600/10000], Loss: 0.000000\n",
      "Epoch [1700/10000], Loss: 0.000000\n",
      "Epoch [1800/10000], Loss: 0.000000\n",
      "Epoch [1900/10000], Loss: 0.000000\n",
      "Epoch [2000/10000], Loss: 0.000000\n",
      "Epoch [2100/10000], Loss: 0.000000\n",
      "Epoch [2200/10000], Loss: 0.000000\n",
      "Epoch [2300/10000], Loss: 0.000000\n",
      "Epoch [2400/10000], Loss: 0.000000\n",
      "Epoch [2500/10000], Loss: 0.000000\n",
      "Epoch [2600/10000], Loss: 0.000000\n",
      "Epoch [2700/10000], Loss: 0.000000\n",
      "Epoch [2800/10000], Loss: 0.000000\n",
      "Epoch [2900/10000], Loss: 0.000000\n",
      "Epoch [3000/10000], Loss: 0.000000\n",
      "Epoch [3100/10000], Loss: 0.000000\n",
      "Epoch [3200/10000], Loss: 0.000000\n",
      "Epoch [3300/10000], Loss: 0.000000\n",
      "Epoch [3400/10000], Loss: 0.000000\n",
      "Epoch [3500/10000], Loss: 0.000000\n",
      "Epoch [3600/10000], Loss: 0.000000\n",
      "Epoch [3700/10000], Loss: 0.000000\n",
      "Epoch [3800/10000], Loss: 0.000000\n",
      "Epoch [3900/10000], Loss: 0.000000\n",
      "Epoch [4000/10000], Loss: 0.000000\n",
      "Epoch [4100/10000], Loss: 0.000000\n",
      "Epoch [4200/10000], Loss: 0.000000\n",
      "Epoch [4300/10000], Loss: 0.000000\n",
      "Epoch [4400/10000], Loss: 0.000000\n",
      "Epoch [4500/10000], Loss: 0.000000\n",
      "Epoch [4600/10000], Loss: 0.000000\n",
      "Epoch [4700/10000], Loss: 0.000000\n",
      "Epoch [4800/10000], Loss: 0.000000\n",
      "Epoch [4900/10000], Loss: 0.000000\n",
      "Epoch [5000/10000], Loss: 0.000000\n",
      "Epoch [5100/10000], Loss: 0.000000\n",
      "Epoch [5200/10000], Loss: 0.000001\n",
      "Epoch [5300/10000], Loss: 0.000000\n",
      "Epoch [5400/10000], Loss: 0.000000\n",
      "Epoch [5500/10000], Loss: 0.000001\n",
      "Epoch [5600/10000], Loss: 0.000000\n",
      "Epoch [5700/10000], Loss: 0.000000\n",
      "Epoch [5800/10000], Loss: 0.000001\n",
      "Epoch [5900/10000], Loss: 0.000000\n",
      "Epoch [6000/10000], Loss: 0.000000\n",
      "Epoch [6100/10000], Loss: 0.000000\n",
      "Epoch [6200/10000], Loss: 0.000012\n",
      "Epoch [6300/10000], Loss: 0.000000\n",
      "Epoch [6400/10000], Loss: 0.000000\n",
      "Epoch [6500/10000], Loss: 0.000000\n",
      "Epoch [6600/10000], Loss: 0.000000\n",
      "Epoch [6700/10000], Loss: 0.000000\n",
      "Epoch [6800/10000], Loss: 0.000000\n",
      "Epoch [6900/10000], Loss: 0.000005\n",
      "Epoch [7000/10000], Loss: 0.000000\n",
      "Epoch [7100/10000], Loss: 0.000000\n",
      "Epoch [7200/10000], Loss: 0.000043\n",
      "Epoch [7300/10000], Loss: 0.000000\n",
      "Epoch [7400/10000], Loss: 0.000000\n",
      "Epoch [7500/10000], Loss: 0.000000\n",
      "Epoch [7600/10000], Loss: 0.000000\n",
      "Epoch [7700/10000], Loss: 0.000000\n",
      "Epoch [7800/10000], Loss: 0.000000\n",
      "Epoch [7900/10000], Loss: 0.000000\n",
      "Epoch [8000/10000], Loss: 0.000000\n",
      "Epoch [8100/10000], Loss: 0.000000\n",
      "Epoch [8200/10000], Loss: 0.000010\n",
      "Epoch [8300/10000], Loss: 0.000000\n",
      "Epoch [8400/10000], Loss: 0.000000\n",
      "Epoch [8500/10000], Loss: 0.000000\n",
      "Epoch [8600/10000], Loss: 0.000000\n",
      "Epoch [8700/10000], Loss: 0.000000\n",
      "Epoch [8800/10000], Loss: 0.000000\n",
      "Epoch [8900/10000], Loss: 0.000099\n",
      "Epoch [9000/10000], Loss: 0.000000\n",
      "Epoch [9100/10000], Loss: 0.000000\n",
      "Epoch [9200/10000], Loss: 0.000000\n",
      "Epoch [9300/10000], Loss: 0.000000\n",
      "Epoch [9400/10000], Loss: 0.000000\n",
      "Epoch [9500/10000], Loss: 0.000000\n",
      "Epoch [9600/10000], Loss: 0.000005\n",
      "Epoch [9700/10000], Loss: 0.000000\n",
      "Epoch [9800/10000], Loss: 0.000000\n",
      "Epoch [9900/10000], Loss: 0.000000\n",
      "Epoch [10000/10000], Loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "train_model(model_tF, criterion, optimizer_tF, x_train_tF, y_train_tF, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "430b7332-ab5e-4ef5-a853-ba8c503b4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_tF, weights_w1_tF, b2_tF, weights_w2_tF = extract_model_params(model_tF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccecfe0c-73c4-4d3d-a1ba-e1a026fe0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_tF = get_NN_analytical_integral(alpha, beta, b1_tF, b2_tF, weights_w1_tF, weights_w2_tF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84cadd0b-2a34-4456-ae11-e2b099809360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of 1.2 of the trained neural network model is: 0.000197\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of 1.2 of the trained neural network model is: {float(integral_tF):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e360a90-7888-4138-bac0-284b5be7e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mult = integral_tF * integral_alpha_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7459e22c-16d4-48c5-a087-129101416575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result for integral multiplication is is: 0.000098\n"
     ]
    }
   ],
   "source": [
    "print(f\"The result for integral multiplication is is: {float(test_mult):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ff511a2-ba33-4e83-b72d-e21f3bb98636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4102779066666721, 8.659999456000012)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR = RR_func()\n",
    "D = D_func()\n",
    "D, RR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf5ec2-a56b-4fc7-ad7e-f6559dac7857",
   "metadata": {},
   "source": [
    "## Integration of function 1.2.1:\n",
    "\n",
    "$ \\frac{t^m}{(1+t)^n}, m = 2, n = 2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "934d5823-6ad7-48b3-98b7-3c46f40b75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_t = MLP(input_size, hidden_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_t = optim.Adam(model_t.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb0dda38-782c-4225-9513-c5f9f4295d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_t, y_train_t = generate_data(t_func, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7341ddcd-5786-4954-a709-4ff821321a42",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.000202\n",
      "Epoch [200/10000], Loss: 0.000031\n",
      "Epoch [300/10000], Loss: 0.000031\n",
      "Epoch [400/10000], Loss: 0.000030\n",
      "Epoch [500/10000], Loss: 0.000030\n",
      "Epoch [600/10000], Loss: 0.000029\n",
      "Epoch [700/10000], Loss: 0.000029\n",
      "Epoch [800/10000], Loss: 0.000029\n",
      "Epoch [900/10000], Loss: 0.000028\n",
      "Epoch [1000/10000], Loss: 0.000028\n",
      "Epoch [1100/10000], Loss: 0.000027\n",
      "Epoch [1200/10000], Loss: 0.000027\n",
      "Epoch [1300/10000], Loss: 0.000026\n",
      "Epoch [1400/10000], Loss: 0.000026\n",
      "Epoch [1500/10000], Loss: 0.000025\n",
      "Epoch [1600/10000], Loss: 0.000025\n",
      "Epoch [1700/10000], Loss: 0.000024\n",
      "Epoch [1800/10000], Loss: 0.000024\n",
      "Epoch [1900/10000], Loss: 0.000023\n",
      "Epoch [2000/10000], Loss: 0.000023\n",
      "Epoch [2100/10000], Loss: 0.000022\n",
      "Epoch [2200/10000], Loss: 0.000022\n",
      "Epoch [2300/10000], Loss: 0.000021\n",
      "Epoch [2400/10000], Loss: 0.000021\n",
      "Epoch [2500/10000], Loss: 0.000021\n",
      "Epoch [2600/10000], Loss: 0.000020\n",
      "Epoch [2700/10000], Loss: 0.000020\n",
      "Epoch [2800/10000], Loss: 0.000019\n",
      "Epoch [2900/10000], Loss: 0.000019\n",
      "Epoch [3000/10000], Loss: 0.000018\n",
      "Epoch [3100/10000], Loss: 0.000017\n",
      "Epoch [3200/10000], Loss: 0.000017\n",
      "Epoch [3300/10000], Loss: 0.000016\n",
      "Epoch [3400/10000], Loss: 0.000016\n",
      "Epoch [3500/10000], Loss: 0.000015\n",
      "Epoch [3600/10000], Loss: 0.000015\n",
      "Epoch [3700/10000], Loss: 0.000014\n",
      "Epoch [3800/10000], Loss: 0.000014\n",
      "Epoch [3900/10000], Loss: 0.000013\n",
      "Epoch [4000/10000], Loss: 0.000013\n",
      "Epoch [4100/10000], Loss: 0.000012\n",
      "Epoch [4200/10000], Loss: 0.000012\n",
      "Epoch [4300/10000], Loss: 0.000012\n",
      "Epoch [4400/10000], Loss: 0.000011\n",
      "Epoch [4500/10000], Loss: 0.000011\n",
      "Epoch [4600/10000], Loss: 0.000011\n",
      "Epoch [4700/10000], Loss: 0.000010\n",
      "Epoch [4800/10000], Loss: 0.000010\n",
      "Epoch [4900/10000], Loss: 0.000010\n",
      "Epoch [5000/10000], Loss: 0.000010\n",
      "Epoch [5100/10000], Loss: 0.000009\n",
      "Epoch [5200/10000], Loss: 0.000009\n",
      "Epoch [5300/10000], Loss: 0.000009\n",
      "Epoch [5400/10000], Loss: 0.000008\n",
      "Epoch [5500/10000], Loss: 0.000008\n",
      "Epoch [5600/10000], Loss: 0.000008\n",
      "Epoch [5700/10000], Loss: 0.000007\n",
      "Epoch [5800/10000], Loss: 0.000007\n",
      "Epoch [5900/10000], Loss: 0.000007\n",
      "Epoch [6000/10000], Loss: 0.000006\n",
      "Epoch [6100/10000], Loss: 0.000006\n",
      "Epoch [6200/10000], Loss: 0.000006\n",
      "Epoch [6300/10000], Loss: 0.000006\n",
      "Epoch [6400/10000], Loss: 0.000005\n",
      "Epoch [6500/10000], Loss: 0.000007\n",
      "Epoch [6600/10000], Loss: 0.000005\n",
      "Epoch [6700/10000], Loss: 0.000005\n",
      "Epoch [6800/10000], Loss: 0.000004\n",
      "Epoch [6900/10000], Loss: 0.000004\n",
      "Epoch [7000/10000], Loss: 0.000004\n",
      "Epoch [7100/10000], Loss: 0.000004\n",
      "Epoch [7200/10000], Loss: 0.000004\n",
      "Epoch [7300/10000], Loss: 0.000003\n",
      "Epoch [7400/10000], Loss: 0.000003\n",
      "Epoch [7500/10000], Loss: 0.000003\n",
      "Epoch [7600/10000], Loss: 0.000003\n",
      "Epoch [7700/10000], Loss: 0.000003\n",
      "Epoch [7800/10000], Loss: 0.000003\n",
      "Epoch [7900/10000], Loss: 0.000003\n",
      "Epoch [8000/10000], Loss: 0.000003\n",
      "Epoch [8100/10000], Loss: 0.000003\n",
      "Epoch [8200/10000], Loss: 0.000003\n",
      "Epoch [8300/10000], Loss: 0.000002\n",
      "Epoch [8400/10000], Loss: 0.000002\n",
      "Epoch [8500/10000], Loss: 0.000002\n",
      "Epoch [8600/10000], Loss: 0.000002\n",
      "Epoch [8700/10000], Loss: 0.000003\n",
      "Epoch [8800/10000], Loss: 0.000002\n",
      "Epoch [8900/10000], Loss: 0.000002\n",
      "Epoch [9000/10000], Loss: 0.000014\n",
      "Epoch [9100/10000], Loss: 0.000002\n",
      "Epoch [9200/10000], Loss: 0.000002\n",
      "Epoch [9300/10000], Loss: 0.000008\n",
      "Epoch [9400/10000], Loss: 0.000002\n",
      "Epoch [9500/10000], Loss: 0.000002\n",
      "Epoch [9600/10000], Loss: 0.000002\n",
      "Epoch [9700/10000], Loss: 0.000002\n",
      "Epoch [9800/10000], Loss: 0.000002\n",
      "Epoch [9900/10000], Loss: 0.000002\n",
      "Epoch [10000/10000], Loss: 0.000003\n"
     ]
    }
   ],
   "source": [
    "train_model(model_t, criterion, optimizer_t, x_train_t, y_train_t, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db26ffde-7d71-4543-821d-1f452dc11c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_t, weights_w1_t, b2_t, weights_w2_t = extract_model_params(model_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8daeb58e-1098-431a-93a8-4c5c0bd0d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_t = get_NN_analytical_integral(alpha, beta, b1_t, b2_t, weights_w1_t, weights_w2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0570d35f-9662-4c78-b96d-83d947b3012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The analytical integral of 1.2.1 of the trained neural network model is: 0.113035\n"
     ]
    }
   ],
   "source": [
    "print(f\"The analytical integral of 1.2.1 of the trained neural network model is: {float(integral_t):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "088caa65-ea91-4449-a855-0aef75503093",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_integral_t = 3 / 2 - np.log(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d675c2e-496b-4e04-be21-8a40f78a5821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true 1.2.1 integral is: 0.113706\n"
     ]
    }
   ],
   "source": [
    "print(f\"The true 1.2.1 integral is: {float(true_integral_t):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
